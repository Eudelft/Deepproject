{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproduction for \"Driver Identiﬁcation Based on Vehicle Telematics Data using LSTM-Recurrent Neural Network\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authors:  \n",
    "Daniel Cisneros Acevedo (4657349)  \n",
    "Emre Ünlü (5404290)  \n",
    "Stijn Waltmann (4548035) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this blog is to reproduce the paper [Driver Identification Based on Vehicle Telematics Data using LSTM-Recurrent Neural Network](https://arxiv.org/abs/1911.08030). This paper uses vehicle telematics data (OBD-II) with machine learning tools to classify the driving style of a driver. The proposed model is a Long-Short Term Memory (LSTMs), this is an RNN architectures variant. For this reproduction, our group is assigned to reproduce Figures 9 & 10. These figures compare the accuracy of LTSMs against FCNN, Decision tree, and Random Forest models by inducing increasing levels of noise on the test data. We have chosen to do a mix of reproducing a small portion of the code and using some of the criteria given on Brightspace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "  <img src=\"Figure9.png\" ref=\"Figure 9\" width=\"400\">\n",
    "  <img src=\"Figure10.png\" ref=\"Figure 9\" width=\"480\">\n",
    "  <figcaption>Figure 9 & 10</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting the code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First look at the code it seems a bit messy, with multiple imports and multiple functions defined throughout the code. When running the code we seem to have trouble with X_test_5. Also, the author of the paper mentioned the code could have some issues because it was developed in a different setting.\n",
    "\n",
    "We have copied several functions from the author's main code to our code main_functions.py and added docstrings for further clarification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three datasets from which one is of importance to us. That is the security driving dataset, collected by KIA Motors Corporation car in an uncontrolled environment. This is the only relevant dataset for this reproduction because figures 9 & 10 only contain these data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# import packages\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.style.use('ggplot')\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "from keras.models import load_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# import functions from main.py\n",
    "from main_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data from the Security Driving Dataset is shown below below. There are 94380 datapoints and 54 columns. The \"Class\" represents the driver_id.\n",
    "It's not a bad idea to look at the data distribution of the classes as class imbalance may affect model performance. Note, there are a total of 10 classes, or drivers in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time(s)</th>\n",
       "      <th>Class</th>\n",
       "      <th>PathOrder</th>\n",
       "      <th>Fuel_consumption</th>\n",
       "      <th>Accelerator_Pedal_value</th>\n",
       "      <th>Throttle_position_signal</th>\n",
       "      <th>Short_Term_Fuel_Trim_Bank1</th>\n",
       "      <th>Intake_air_pressure</th>\n",
       "      <th>Filtered_Accelerator_Pedal_value</th>\n",
       "      <th>Absolute_throttle_position</th>\n",
       "      <th>...</th>\n",
       "      <th>Converter_clutch</th>\n",
       "      <th>Gear_Selection</th>\n",
       "      <th>Vehicle_speed</th>\n",
       "      <th>Acceleration_speed_-_Longitudinal</th>\n",
       "      <th>Indication_of_brake_switch_ON/OFF</th>\n",
       "      <th>Master_cylinder_pressure</th>\n",
       "      <th>Calculated_road_gradient</th>\n",
       "      <th>Acceleration_speed_-_Lateral</th>\n",
       "      <th>Steering_wheel_speed</th>\n",
       "      <th>Steering_wheel_angle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>268.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>13.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-8.5</td>\n",
       "      <td>1</td>\n",
       "      <td>325.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-8.8</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>243.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>13.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>217.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>13.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>204.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>13.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>217.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>13.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94375</th>\n",
       "      <td>2564</td>\n",
       "      <td>D</td>\n",
       "      <td>2</td>\n",
       "      <td>345.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-13.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94376</th>\n",
       "      <td>2565</td>\n",
       "      <td>D</td>\n",
       "      <td>2</td>\n",
       "      <td>345.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>8.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>-13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94377</th>\n",
       "      <td>2566</td>\n",
       "      <td>D</td>\n",
       "      <td>2</td>\n",
       "      <td>345.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>12.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-13.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94378</th>\n",
       "      <td>2567</td>\n",
       "      <td>D</td>\n",
       "      <td>2</td>\n",
       "      <td>332.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.7</td>\n",
       "      <td>6.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-13.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94379</th>\n",
       "      <td>2568</td>\n",
       "      <td>D</td>\n",
       "      <td>2</td>\n",
       "      <td>281.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>8.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>-13.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94380 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Time(s) Class  PathOrder  Fuel_consumption  Accelerator_Pedal_value  \\\n",
       "0            1     A          1             268.8                      0.0   \n",
       "1            2     A          1             243.2                      0.0   \n",
       "2            3     A          1             217.6                      0.0   \n",
       "3            4     A          1             204.8                      0.0   \n",
       "4            5     A          1             217.6                      0.0   \n",
       "...        ...   ...        ...               ...                      ...   \n",
       "94375     2564     D          2             345.6                      0.0   \n",
       "94376     2565     D          2             345.6                      0.0   \n",
       "94377     2566     D          2             345.6                      0.0   \n",
       "94378     2567     D          2             332.8                      0.0   \n",
       "94379     2568     D          2             281.6                      0.0   \n",
       "\n",
       "       Throttle_position_signal  Short_Term_Fuel_Trim_Bank1  \\\n",
       "0                           5.2                         0.0   \n",
       "1                           6.1                         0.0   \n",
       "2                           5.2                         0.0   \n",
       "3                           4.7                         0.0   \n",
       "4                           5.7                         0.0   \n",
       "...                         ...                         ...   \n",
       "94375                       6.6                         7.0   \n",
       "94376                       6.6                         7.0   \n",
       "94377                       6.6                         7.0   \n",
       "94378                       5.7                         6.3   \n",
       "94379                       5.2                         5.5   \n",
       "\n",
       "       Intake_air_pressure  Filtered_Accelerator_Pedal_value  \\\n",
       "0                       33                                 0   \n",
       "1                       40                                 0   \n",
       "2                       41                                 0   \n",
       "3                       38                                 0   \n",
       "4                       40                                 0   \n",
       "...                    ...                               ...   \n",
       "94375                    0                                 0   \n",
       "94376                    0                                 0   \n",
       "94377                    0                                 0   \n",
       "94378                    0                                 0   \n",
       "94379                    0                                 0   \n",
       "\n",
       "       Absolute_throttle_position  ...  Converter_clutch  Gear_Selection  \\\n",
       "0                            13.3  ...                 0               0   \n",
       "1                            13.7  ...                 0               0   \n",
       "2                            13.7  ...                 0               0   \n",
       "3                            13.3  ...                 0               0   \n",
       "4                            13.7  ...                 0               0   \n",
       "...                           ...  ...               ...             ...   \n",
       "94375                        14.5  ...                 0               7   \n",
       "94376                        14.5  ...                 0               7   \n",
       "94377                        14.5  ...                 0               0   \n",
       "94378                        14.1  ...                 0               0   \n",
       "94379                        13.7  ...                 0               0   \n",
       "\n",
       "       Vehicle_speed  Acceleration_speed_-_Longitudinal  \\\n",
       "0                  0                               -8.5   \n",
       "1                  0                                0.1   \n",
       "2                  0                                0.1   \n",
       "3                  0                                0.1   \n",
       "4                  0                                0.1   \n",
       "...              ...                                ...   \n",
       "94375              0                               -0.2   \n",
       "94376              0                                0.1   \n",
       "94377              0                               -0.2   \n",
       "94378              0                               -0.2   \n",
       "94379              0                               -0.2   \n",
       "\n",
       "       Indication_of_brake_switch_ON/OFF  Master_cylinder_pressure  \\\n",
       "0                                      1                     325.5   \n",
       "1                                      1                       0.9   \n",
       "2                                      1                       0.9   \n",
       "3                                      1                       0.9   \n",
       "4                                      1                       0.9   \n",
       "...                                  ...                       ...   \n",
       "94375                                  2                       2.3   \n",
       "94376                                  2                       8.7   \n",
       "94377                                  2                      12.6   \n",
       "94378                                  2                      13.0   \n",
       "94379                                  2                       8.2   \n",
       "\n",
       "       Calculated_road_gradient  Acceleration_speed_-_Lateral  \\\n",
       "0                           0.0                          -8.8   \n",
       "1                           0.0                          -0.2   \n",
       "2                           0.0                          -0.2   \n",
       "3                           0.0                          -0.2   \n",
       "4                           0.0                          -0.2   \n",
       "...                         ...                           ...   \n",
       "94375                       0.0                           0.0   \n",
       "94376                       0.0                          -0.1   \n",
       "94377                       0.0                           0.0   \n",
       "94378                       0.0                           0.0   \n",
       "94379                       0.0                          -0.1   \n",
       "\n",
       "       Steering_wheel_speed  Steering_wheel_angle  \n",
       "0                         0                  -3.4  \n",
       "1                         0                  -3.6  \n",
       "2                         0                  -3.6  \n",
       "3                         0                  -3.6  \n",
       "4                         0                  -3.5  \n",
       "...                     ...                   ...  \n",
       "94375                     0                 -13.2  \n",
       "94376                     0                 -13.0  \n",
       "94377                     0                 -13.2  \n",
       "94378                     0                 -13.3  \n",
       "94379                     0                 -13.3  \n",
       "\n",
       "[94380 rows x 54 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data\n",
    "df = pd.read_csv('./Data/korea_vehicledata.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class D and B have the highest number of datapoints\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Classes')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAEYCAYAAAB7twADAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAAv8ElEQVR4nO3de1gU9eI/8PewuMCyICzXMEwRSSAQFc3bAUS6nOx0OGRaann9FnLy2s1L37TUtGMqgponUczU8pJiZZ0KCbwg3/CCpajhUUsSRFgUEJXLfn5/+GNzFXGV2Qv6fj2Pz+N+ZnbmPQPu29mZnZWEEAJERETNZGPpAEREdG9goRARkSxYKEREJAsWChERyYKFQkREsmChEBGRLFgoZHKnT5+GJEnYvXu3paMYqKiowD/+8Q+0bt0akiTh9OnTRj9XkiSsXbvWdOHMYObMmfD397d0DLOJiorCmDFjLB3jnsZCuceNGDECkiThzTffNBgvLCyEJEnIzMy0TDAr8NFHH2Hv3r3YvXs3ioqK4Ovra7J1rV27FpIkmWz5d+P1119HTk7OHT3HGreDrAcL5T5gb2+PpKQk/Pbbb5aOIrva2tq7fm5BQQGCg4MREhICb29vKBQKGZNZP7VaDXd3d0vHuGPN+ZmTabFQ7gO9e/dG586dMW3atFvOc6u3pfz9/TFz5kz9Y0mSkJycjMGDB8PR0RFt27bF5s2bcfHiRQwdOhROTk7w8/PDF1980eg6+vfvDwcHB/j5+eHzzz83mH7u3DmMGDECHh4ecHJyQp8+fbBz50799MzMTEiShO3bt6Nv376wt7dHSkpKo9tTW1uLKVOmoE2bNlAqlQgKCsL69ev109u1a4eVK1ciIyMDkiQhKirqlvvmxx9/RGhoKOzt7REaGooff/zxpnmmT5+OwMBAqFQq+Pr6Ij4+HhcvXtTnfvHFF/X7T5IkjBgxAgDwww8/ICoqChqNBq1bt0ZkZCR++umnW2YBgNWrV8PW1hbp6ekIDg6Gvb09Hn30UeTl5RnM980336Bbt26ws7ODp6cnEhIScOnSJf30G9/yani8bds2dOrUCY6OjoiKikJBQcFtt+NGDb9Pa9euNdvPHACWLl2KoKAg/TY/++yzt5zXmH2fkpKCwMBA2NvbQ6PRICIiAoWFhQCuvWU6cuRIeHt7w87ODr6+vpg8efIt13dfEHRPGz58uOjfv7/YuXOnkCRJ5ObmCiGEOHPmjAAgfvzxRyGEEKdOnRIAxK5duwye36FDBzFjxgz9YwDCy8tLrF69WhQUFIixY8cKe3t78eSTT4rU1FRRUFAgXn31VaFSqURpaanBsh944AGxdu1acezYMTF9+nRhY2MjDhw4IIQQorq6WgQGBoq4uDiRm5srCgoKxOzZs4VSqRT5+flCCCF+/PFHAUA8/PDD4ssvvxQnT54UZ86caXS7X3/9daHRaMTGjRvF8ePHxZw5c4QkSSI9PV0IIURJSYkYNGiQ+Mtf/iKKiopEWVlZo8v5448/hEqlEiNGjBBHjhwR33//vQgJCREAxKeffqqfb9asWWLnzp3i1KlTIj09XTz88MPipZdeEkIIcfXqVbFkyRIBQBQVFYmioiJx4cIFIYQQW7ZsERs2bBDHjh0Thw8fFqNHjxaurq76fdeY1NRUIUmS6NKli8jMzBSHDh0SAwYMED4+PqK6uloIIcShQ4eEQqEQEydOFEePHhXffPON8PX1FcOGDdMvZ8aMGaJDhw4Gj1UqlXjiiSfEvn37RF5enujatavo27fvbbfjRpb4mb/zzjvC0dFRJCcni+PHj4v9+/eL2bNn66dHRkaK0aNH6x/fbt/v27dPKBQK8cknn4jTp0+Ln3/+WaxYsUK//nHjxonQ0FCRk5MjfvvtN7Fnzx7x8ccf3/Lndj9godzjGgpFCCFiY2NFZGSkEKJ5hTJhwgT945KSEgFAvPrqq/oxrVYrAIivvvrKYNlvv/22wbJ79eqlf4FLTU0Vbdq0EbW1tQbz9OvXT7++hheXNWvWNLnNly5dEkqlUixdutRgPDY2VvTr16/RfXMr06dPF23btjXI9dVXX91UKDfasmWLUCqVor6+XgghxKeffiqM+f9bfX29cHFxEWvXrr3lPKmpqQKAvhyFuLbPHR0dRUpKihBCiGHDhonu3bsbPC8tLU1IkiROnz4thGi8UBQKhSgpKdGPff7550KSJHH58uU72g5z/8yrqqqEvb29mD9//i3nubFQbnTjvt+yZYtwdnYWFy9ebHT+Z555RgwfPrzJXPcbvuV1H/nggw+wZ88efPnll81aTufOnfV/9/DwgEKhQGhoqH7M1dUVSqUSJSUlBs/r1auXweM+ffrgyJEjAIDc3FwUFxfDxcUFarVa/2fXrl36t1wa9OjRo8l8J06cQE1NDSIiIgzGIyMj9eszVn5+Pnr06AFbW1v9WN++fW+ab8uWLYiIiICPjw/UajWGDh2KmpoaFBcXN7n8U6dO4cUXX4S/vz+cnZ3h7OyMixcvGnW+6/r96erqisDAQP32HTlypNHtF0IgPz//lsv08fGBh4eHwWMhxE0/S2OZ62d+5MgRXLlyBY8//rjR2W637x977DH4+fmhffv2eP755/Hxxx+jtLRU//yEhARs3rwZjzzyCCZMmIBvv/0WOp3O6PXfi2xvPwvdKwICAvDKK6/grbfewrfffmswzcbm2v8txA03n27sBGirVq1uOyZJ0h3949LpdAgMDMTWrVtvmqZSqQweOzo6Gr1cc/i///s/PPfcc5g6dSrmz58PV1dX5OTkYPjw4aipqWnyuU8//TTc3d2xdOlS+Pr6QqlUom/fvrd9nqkolUqDxw1XdJnihdLSP/Pb7Xu1Wo19+/Zhz549SE9Px/Lly/Hmm29ix44d6NatG5544gn8/vvv+O6775CZmYlhw4YhJCQEO3bsuO8u8GjAI5T7zIwZM3D27Fl8/PHHBuMN/ys9e/asfqykpAR//PGHbOu+8RLV7OxsBAUFAQDCw8Nx8uRJODs7w9/f3+CPj4/PHa3H398fdnZ2Bid3ASArKwuPPPLIHS0rKCgIP/30E+rr6/Vje/bsMZhn9+7dcHd3x+zZs/Hoo48iICBAf+K2QcML9fXLKSsrQ35+PqZMmYInnngCQUFBsLe3N/po4Pr9eeHCBRw9elS/P4ODgxvdfkmSEBwcbNTyG9PYdhibETDdz7xh333//fdGzW/svlcoFIiIiMB7772H/fv344EHHjC4uEOj0eCFF17Av//9b2zfvh1ZWVlNHgHe63iEcp/x8PDAlClTMGvWLINxBwcH9OnTB//617/QqVMn1NXVYfr06bCzs5Nt3StXrkSnTp0QHh6OtWvXYu/evUhOTgYADB06FIsWLcKAAQMwZ84cBAQE4Ny5c8jIyEBgYCBiY2ONXo9KpcL48ePxv//7v/Dw8EDnzp2xefNmbNu2DT/88MMdZR47diwWLlyIl19+Ga+//jrOnj2L6dOnG8zz8MMP4/z581i5ciX69euH3bt3Y9myZQbztG/fHgDw5Zdfom/fvnBwcICrqys8PDywYsUKdOjQAWVlZXjzzTfh4OBw21wNny1auHAhXF1dMX36dDg5OWHIkCEAgDfeeANdu3bFpEmT8Morr+D06dMYN24chg4dirZt297RPrjddqjV6lvOb66fuVqtxmuvvYaZM2fCwcEBjz32GC5fvoxvvvkGU6dOvWl+Y/b9tm3bcPLkSURERMDDwwP79+/HmTNn9IU4ffp0dOvWDcHBwbCxscG6deugVqubtX9bPAufwyETa+zE8+XLl4Wvr6/BSXkhhDh+/LiIiIgQKpVK+Pv7iy+++KLRk/I3noxWKBQiNTXVYMzOzk6sWLFCCPHnCdo1a9aIyMhIYWdnJ9q1ayfWrVtn8JzS0lIRHx8vfHx8RKtWrYSPj4+IjY3VXxXUcIL2Vlf5XK+mpka89dZb+mUFBgbetD5jTsoLIUR6erp45JFHhFKpFMHBwWLHjh037Ye3335beHp6CpVKJf7617+K9evXCwDi1KlT+nkmTJggPDw8BAD9ydzMzEwRGhoq7OzsREBAgNi8efNN+/xGqampQqFQiO+++0506tRJKJVK0b17d7F//36D+bZv3y66du0qlEqlcHd3F/Hx8aKqqko/vbGT8tc/FkKIXbt2GbUdN7LEz1yn04nExEQREBAgWrVqJTw9PcXAgQP10288KX+7fZ+VlSX69esn3N3dhZ2dnfD39xdz587VP/+9994TwcHBwtHRUTg7O4uIiIibLmq530hC8BsbiVqS1atXY8yYMairq7N0lFs6ffo02rdvj127djV6EQPdm3gOhYiIZMFCISIiWfAtLyIikgWPUIiISBYsFCIikgULhYiIZHHff7Dx+k+G3yl3d3eDe/tYijXksIYM1pLDGjJYSw5ryGAtOawhg1w5bnUnAx6hEBGRLFgoREQkCxYKERHJgoVCRESyYKEQEZEsWChERCQLFgoREcmChUJERLK47z/YSC3L39cda9bztw3tJFMSIroRj1CIiEgWLBQiIpIFC4WIiGTBQiEiIlmwUIiISBa8yqsF4JVNRNQS8AiFiIhkwUIhIiJZsFCIiEgWLBQiIpIFC4WIiGTBQiEiIlmwUIiISBYsFCIikgULhYiIZGGWT8ovW7YMBw4cQOvWrbFgwQIAwKeffor9+/fD1tYWXl5eSEhIgKOjIwBg69atyMjIgI2NDUaOHImwsDAAQF5eHlJTU6HT6dC/f3/ExsYCAEpKSpCYmIjKykr4+flh3LhxsLXlTQCIiMzJLEcoUVFRmDZtmsFYaGgoFixYgA8//BAPPPAAtm7dCgAoLCxEdnY2Fi5ciOnTp2PlypXQ6XTQ6XRYuXIlpk2bhkWLFmHPnj0oLCwEAKxduxYDBgxAcnIyHB0dkZGRYY7NIiKi65ilUIKCgqBWqw3GOnfuDIVCAQAICAiAVqsFAOTm5qJ3795o1aoVPD094e3tjRMnTuDEiRPw9vaGl5cXbG1t0bt3b+Tm5kIIgSNHjqBnz54ArpVXbm6uOTaLiIiuYxXvC2VkZKB3794AAK1Wi44dO+qnaTQafdm4ubnpx93c3FBQUIDKykqoVCp9OV0/f2PS09ORnp4OAJg3bx7c3d3vOretrW2znm8u5sjIffEna9kX1pDDGjJYSw5ryGDqHBYvlC1btkChUOAvf/mLWdYXExODmJgY/ePS0tK7Xpa7u3uznm8u5sjIffEna9kX1pDDGjJYSw5ryCBXDh8fn0bHLXqVV2ZmJvbv34/x48dDkiQA144wysrK9PNotVpoNJqbxsvKyqDRaODk5ITq6mrU19cbzE9EROZlsULJy8vDtm3b8NZbb8HOzk4/Hh4ejuzsbNTW1qKkpARFRUXw9/dHhw4dUFRUhJKSEtTV1SE7Oxvh4eGQJAnBwcHIyckBcK2kwsPDLbVZRET3LbO85ZWYmIj8/HxUVlYiPj4egwYNwtatW1FXV4dZs2YBADp27IiXX34Zvr6+6NWrFyZPngwbGxuMHj0aNjbXem/UqFGYM2cOdDod+vXrB19fXwDA0KFDkZiYiM8//xzt27dHdHS0OTaLiIiuY5ZCmThx4k1jTb3ox8XFIS4u7qbxrl27omvXrjeNe3l5Ye7cuc3KSEREzcNPyhMRkSxYKEREJAsWChERyYKFQkREsmChEBGRLFgoREQkCxYKERHJgoVCRESyYKEQEZEsWChERCQLi9++noju3N/XHWv2MrYN7SRDEqI/8QiFiIhkwUIhIiJZsFCIiEgWLBQiIpIFC4WIiGTBQiEiIlmwUIiISBYsFCIikgULhYiIZMFCISIiWbBQiIhIFma5l9eyZctw4MABtG7dGgsWLAAAVFVVYdGiRTh//jw8PDwwadIkqNVqCCGQmpqKgwcPws7ODgkJCfDz8wMAZGZmYsuWLQCAuLg4REVFAQBOnjyJpUuXoqamBl26dMHIkSMhSZI5No2IiP4/sxyhREVFYdq0aQZjaWlpCAkJQVJSEkJCQpCWlgYAOHjwIIqLi5GUlISXX34ZKSkpAK4V0ObNm/H+++/j/fffx+bNm1FVVQUAWLFiBV555RUkJSWhuLgYeXl55tgsIiK6jlkKJSgoCGq12mAsNzcXkZGRAIDIyEjk5uYCAPbt24eIiAhIkoSAgABcunQJ5eXlyMvLQ2hoKNRqNdRqNUJDQ5GXl4fy8nJcvnwZAQEBkCQJERER+mUREZH5WOwcysWLF+Hq6goAcHFxwcWLFwEAWq0W7u7u+vnc3Nyg1Wqh1Wrh5uamH9doNI2ON8xPRETmZRXfhyJJktnOeaSnpyM9PR0AMG/ePIPyulO2trbNer65mCMj98WfuC/+ZC37whpyWEMGU+ewWKG0bt0a5eXlcHV1RXl5OZydnQFcO/IoLS3Vz1dWVgaNRgONRoP8/Hz9uFarRVBQEDQaDcrKym6a/1ZiYmIQExOjf3z9uu6Uu7t7s55vLubIyH3xJ+6LP1nLvrCGHNaQQa4cPj4+jY5brFDCw8ORlZWF2NhYZGVloXv37vrx//znP+jTpw8KCgqgUqng6uqKsLAwfPbZZ/oT8YcOHcKQIUOgVqvh4OCAX3/9FR07dsTOnTvx5JNPWmqziMjM+O2V1sMshZKYmIj8/HxUVlYiPj4egwYNQmxsLBYtWoSMjAz9ZcMA0KVLFxw4cADjx4+HUqlEQkICAECtVuPZZ5/F1KlTAQADBw7Un+gfM2YMli1bhpqaGoSFhaFLly7m2CwiIrqOWQpl4sSJjY6/8847N41JkoQxY8Y0On90dDSio6NvGu/QoYP+8y1ERGQZ/KQ8ERHJgoVCRESyYKEQEZEsWChERCQLFgoREcmChUJERLJgoRARkSxYKEREJAsWChERyeKuCuXw4cMGN2okIiIyqlBmzJiBY8eu3YAtLS0NixcvxuLFi/Vfx0tERGRUoZw5cwYBAQEAgB07dmDGjBmYM2cOfvjhB5OGIyKilsOom0MKIQAAxcXFAIAHH3wQAHDp0iUTxSIiojtl6Vv5G1UoDz/8MFatWoXy8nL995YUFxfDycnprldMRET3FqPe8vrnP/8JlUqFhx56CIMGDQIAnD17Fk899ZRJwxERUcth1BHK4cOHMWTIEIOxrl27IicnxyShiIio5THqCGX58uWNjv/73/+WNQwREbVcTR6hnDt3DgCg0+lQUlKiPznfME2pVJo2HRERtRhNFsr48eP1fx83bpzBNBcXFzz33HOmSUVERC1Ok4WyYcMGANc+2Pjuu++aJRCRtbP0pZlE1sqocygsEyIiuh2jrvIqKSnBZ599htOnT+PKlSsG0z766COTBCMiopbFqEJZvHgxvLy88NJLL8HOzs7UmYiIqAUyqlAKCwsxa9Ys2NjIf7f7r7/+GhkZGZAkCb6+vkhISMCFCxeQmJiIyspK+Pn5Ydy4cbC1tUVtbS2WLFmCkydPwsnJCRMnToSnpycAYOvWrcjIyICNjQ1GjhyJsLAw2bMSEdGtGdUQgYGBOH36tOwr12q1+PbbbzFv3jwsWLAAOp0O2dnZWLt2LQYMGIDk5GQ4OjoiIyMDAJCRkQFHR0ckJydjwIABWLduHYBrhZednY2FCxdi+vTpWLlyJXQ6nex5iYjo1ow6QvHw8MCcOXPQo0cPuLi4GEwbPHhwswLodDrU1NRAoVCgpqYGLi4uOHLkCCZMmAAAiIqKwqZNm/D4449j3759+kuVe/bsiVWrVkEIgdzcXPTu3RutWrWCp6cnvL29ceLECf0dkomIyPSMKpSrV6+iW7duqK+vR1lZmWwr12g0+Nvf/oaxY8dCqVSic+fO8PPzg0qlgkKh0M+j1WoBXDuicXNzAwAoFAqoVCpUVlZCq9WiY8eOBstteM6N0tPTkZ6eDgCYN28e3N3d7zq/ra1ts55vLubIyH1xZ6whB38v/sR98admvSYaM1NCQsJdr6ApVVVVyM3NxdKlS6FSqbBw4ULk5eWZZF0NYmJiEBMTo39cWlp618tyd3dv1vPNxRwZuS/ujDXk4O/Fn7gv/mRMRh8fn0bHb1koJSUl+hPeDbdgaYyXl9dtV34rv/zyCzw9PeHs7AwAePTRR3H8+HFUV1ejvr4eCoUCWq0WGo0GwLUjj7KyMri5uaG+vh7V1dVwcnLSjze4/jlERGQetyyU119/HWvWrAFgeAuWGzV8mv5uuLu7o6CgAFevXoVSqcQvv/yCDh06IDg4GDk5OejTpw8yMzMRHh4OAOjWrRsyMzMREBCAnJwcBAcHQ5IkhIeHIykpCU8//TTKy8tRVFQEf3//u85FRHSneAeFJgqloUyA5pVGUzp27IiePXvirbfegkKhQLt27RATE4OuXbsiMTERn3/+Odq3b4/o6GgAQHR0NJYsWYJx48ZBrVZj4sSJAABfX1/06tULkydPho2NDUaPHm2SS5yJiOjWjDqH0qC0tFT/dpJcJ5cGDRqk/9KuBl5eXpg7d+5N8yqVSkyePLnR5cTFxSEuLk6WTEREdOeMKpTy8nIkJibi119/hZOTEyorKxEQEIAJEybwXAUREQEw8oONK1aswEMPPYTU1FR8/PHHSE1NRbt27bBixQpT5yMiohbCqCOU48ePY/LkybC1vTa7vb09hg0bhvj4eJOGI+vBE47UGP5e0PWMOkJxdHREYWGhwdjZs2ehUqlMEoqIiFoeo45QnnnmGcyaNQvR0dHw8PDA+fPnkZmZ2ezbrhAR0b3DqEKJiYmBt7c3du/ejd9//x2urq4YP348QkJCTJ2PiIhaiCYLRQiBHTt24Pfff4efn999d86E7w8TERmvyXMon376KTZu3IgLFy5g/fr12Lhxo7lyERFRC9PkEcrevXsxc+ZM+Pj4oLCwEP/6179u+hAiERERcJsjlOrqav1dJR988EFUVVWZJRQREbU8tz2HUlJSAiEEgGtfhnX9Y6B5dxsmIqJ7R5OFcvXqVYwbN85g7MbHprpxJBERtSxNFgrLgoiIjMV7vBMRkSxYKEREJAsWChERyYKFQkREsmChEBGRLIy6OWR1dTU2bdqE/Px8VFZWGnwO5aOPPjJZOCIiajmMOkJJSUnBqVOnMHDgQFRVVWHUqFFwd3fHgAEDTJ2PiIhaCKMK5eeff8Zrr72G7t27w8bGBt27d8ekSZOwa9cuU+cjIqIWwqhCEULov53R3t4e1dXVcHFxQXFxsUnDERFRy2HUOZSHHnoI+fn5CAkJQadOnZCSkgJ7e3s88MADzQ5w6dIlLF++HGfOnIEkSRg7dix8fHywaNEinD9/Hh4eHpg0aRLUajWEEEhNTcXBgwdhZ2eHhIQE+Pn5AQAyMzOxZcsWAEBcXByioqKanY2IiIxn1BHKK6+8Ag8PDwDAyJEjoVQqcenSJbz66qvNDpCamoqwsDAkJiZi/vz5aNOmDdLS0hASEoKkpCSEhIQgLS0NAHDw4EEUFxcjKSkJL7/8MlJSUgAAVVVV2Lx5M95//328//772Lx5M++MTERkZkYVSkVFBby9vQEArVu3Rnx8PCZNmoQrV640a+XV1dU4evQooqOjAQC2trZwdHREbm4uIiMjAQCRkZHIzc0FAOzbtw8RERGQJAkBAQG4dOkSysvLkZeXh9DQUKjVaqjVaoSGhiIvL69Z2YiI6M4Y9ZbX7Nmz8cknn9w0PmfOHKSmpt71yktKSuDs7Ixly5bht99+g5+fH0aMGIGLFy/C1dUVAODi4oKLFy8CALRaLdzd3fXPd3Nzg1arhVarhZubm35co9FAq9U2us709HSkp6cDAObNm2ewPFMw9fJbSgbAOnJYQwbAOnJYQwbAOnJYQwbAOnI0J0OThaLT6QBcOynf8KfBuXPnoFAo7nrFAFBfX49Tp05h1KhR6NixI1JTU/VvbzWQJAmSJDVrPdeLiYlBTEyM/nFpaalsy26MqZffUjIA1pHDGjIA1pHDGjIA1pHDGjIA1pHDmAwNX7x4oyYL5YUXXtD//fnnnzeYZmNjg3/84x/G5LslNzc3uLm5oWPHjgCAnj17Ii0tDa1bt0Z5eTlcXV1RXl4OZ2dnANeOPK7f2LKyMmg0Gmg0GuTn5+vHtVotgoKCmpWNiIjuTJOFsmTJEgghMHPmTLz77rv6cUmS4OzsDKVS2ayVu7i4wM3NDWfPnoWPjw9++eUXPPjgg3jwwQeRlZWF2NhYZGVloXv37gCA8PBw/Oc//0GfPn1QUFAAlUoFV1dXhIWF4bPPPtOfiD906BCGDBnSrGxERHRnmiyUhiu7li1bZrIAo0aNQlJSEurq6uDp6YmEhAQIIbBo0SJkZGToLxsGgC5duuDAgQMYP348lEolEhISAABqtRrPPvsspk6dCgAYOHAg1Gq1yTITEdHNjDopD1y7wio/Px8VFRUG4829dLhdu3aYN2/eTePvvPPOTWOSJGHMmDGNLic6Olp/tRgREZmfUZcNb9q0CR9//DF0Oh1ycnKgVqtx6NAh/afniYiIjDpC+fHHH/H222+jbdu2yMzMxIgRI9C3b1988cUXps5HREQthFFHKJcuXULbtm0BXPvwYV1dHfz9/Q2urCIiovubUUco3t7eOHPmDHx9feHr64vvv/9e/6l0IiIiwMhCGTx4MCorKwEAQ4YMQVJSEq5cuXLLE+RERHT/MapQunbtqv97x44dkZycbLJARETUMhlVKIWFhTh69CiqqqqgVqsRGBiIBx980NTZiIioBWmyUIQQ+Oijj5CVlQU3Nze4urpCq9WivLwcERERGDt2rKz32SIioparyUJJT09Hfn4+5syZA39/f/34iRMnsHjxYvzwww94/PHHTR6SiIisX5OXDe/cuRMjR440KBMA8Pf3x4gRI/id8kREpNdkoRQWFt7yrr1BQUEoLCw0SSgiImp5miwUnU4HBweHRqc5ODjovy+FiIioyXMo9fX1OHz48C2ns1CIiKhBk4XSunVrfPTRR7ec3vDFV0RERE0WytKlS82Vg4iIWjijbg5JRER0OywUIiKSBQuFiIhkwUIhIiJZsFCIiEgWLBQiIpIFC4WIiGRh1PehmJpOp8OUKVOg0WgwZcoUlJSUIDExEZWVlfDz88O4ceNga2uL2tpaLFmyBCdPnoSTkxMmTpwIT09PAMDWrVuRkZEBGxsbjBw5EmFhYZbdKCKi+4xVHKF88803aNOmjf7x2rVrMWDAACQnJ8PR0REZGRkAgIyMDDg6OiI5ORkDBgzAunXrAFy7iWV2djYWLlyI6dOnY+XKlbwtDBGRmVm8UMrKynDgwAH0798fwLUv9Tpy5Ah69uwJAIiKikJubi4AYN++fYiKigIA9OzZE4cPH4YQArm5uejduzdatWoFT09PeHt748SJExbZHiKi+5XFC2X16tUYNmyY/psfKysroVKpoFAoAAAajQZarRYAoNVq4ebmBgBQKBRQqVSorKw0GL/xOUREZB4WPYeyf/9+tG7dGn5+fjhy5IhZ1pmeno709HQAwLx58+Du7m7S9Zl6+S0lA2AdOawhA2AdOawhA2AdOawhA2AdOZqTwaKFcvz4cezbtw8HDx5ETU0NLl++jNWrV6O6uhr19fVQKBTQarXQaDQArh15lJWVwc3NDfX19aiuroaTk5N+vMH1z7lRTEwMYmJi9I9LS0tNuo2mXn5LyQBYRw5ryABYRw5ryABYRw5ryABYRw5jMvj4+DQ6btG3vIYMGYLly5dj6dKlmDhxIh555BGMHz8ewcHByMnJAQBkZmYiPDwcANCtWzdkZmYCAHJychAcHAxJkhAeHo7s7GzU1taipKQERUVFN31tMRERmZZVXDZ8o6FDhyIxMRGff/452rdvj+joaABAdHQ0lixZgnHjxkGtVmPixIkAAF9fX/Tq1QuTJ0+GjY0NRo8eDRsbi58eIiK6r1hNoQQHByM4OBgA4OXlhblz5940j1KpxOTJkxt9flxcHOLi4kyakYiIbo3/jSciIlmwUIiISBYsFCIikgULhYiIZMFCISIiWbBQiIhIFiwUIiKSBQuFiIhkwUIhIiJZsFCIiEgWLBQiIpIFC4WIiGTBQiEiIlmwUIiISBYsFCIikgULhYiIZMFCISIiWbBQiIhIFiwUIiKSBQuFiIhkwUIhIiJZsFCIiEgWtpZceWlpKZYuXYoLFy5AkiTExMTgqaeeQlVVFRYtWoTz58/Dw8MDkyZNglqthhACqampOHjwIOzs7JCQkAA/Pz8AQGZmJrZs2QIAiIuLQ1RUlAW3jIjo/mPRQlEoFHjxxRfh5+eHy5cvY8qUKQgNDUVmZiZCQkIQGxuLtLQ0pKWlYdiwYTh48CCKi4uRlJSEgoICpKSk4P3330dVVRU2b96MefPmAQCmTJmC8PBwqNVqS24eEdF9xaJvebm6uuqPMBwcHNCmTRtotVrk5uYiMjISABAZGYnc3FwAwL59+xAREQFJkhAQEIBLly6hvLwceXl5CA0NhVqthlqtRmhoKPLy8iy1WURE9yWrOYdSUlKCU6dOwd/fHxcvXoSrqysAwMXFBRcvXgQAaLVauLu765/j5uYGrVYLrVYLNzc3/bhGo4FWqzXvBhAR3ecs+pZXgytXrmDBggUYMWIEVCqVwTRJkiBJkmzrSk9PR3p6OgBg3rx5BgVlCqZefkvJAFhHDmvIAFhHDmvIAFhHDmvIAFhHjuZksHih1NXVYcGCBfjLX/6CRx99FADQunVrlJeXw9XVFeXl5XB2dgZw7cijtLRU/9yysjJoNBpoNBrk5+frx7VaLYKCghpdX0xMDGJiYvSPr1+eKZh6+S0lA2AdOawhA2AdOawhA2AdOawhA2AdOYzJ4OPj0+i4Rd/yEkJg+fLlaNOmDZ5++mn9eHh4OLKysgAAWVlZ6N69u358586dEELg119/hUqlgqurK8LCwnDo0CFUVVWhqqoKhw4dQlhYmCU2iYjovmXRI5Tjx49j586daNu2Ld544w0AwAsvvIDY2FgsWrQIGRkZ+suGAaBLly44cOAAxo8fD6VSiYSEBACAWq3Gs88+i6lTpwIABg4cyCu8iIjMzKKF0qlTJ2zcuLHRae+8885NY5IkYcyYMY3OHx0djejoaFnzERGR8azmKi8iImrZWChERCQLFgoREcmChUJERLJgoRARkSxYKEREJAsWChERyYKFQkREsmChEBGRLFgoREQkCxYKERHJgoVCRESyYKEQEZEsWChERCQLFgoREcmChUJERLJgoRARkSxYKEREJAsWChERyYKFQkREsmChEBGRLFgoREQkCxYKERHJwtbSAeSUl5eH1NRU6HQ69O/fH7GxsZaORER037hnjlB0Oh1WrlyJadOmYdGiRdizZw8KCwstHYuI6L5xzxTKiRMn4O3tDS8vL9ja2qJ3797Izc21dCwiovuGJIQQlg4hh5ycHOTl5SE+Ph4AsHPnThQUFGD06NEG86WnpyM9PR0AMG/ePLPnJCK6V90zRyjGiomJwbx582QpkylTpsiQqPmsIYc1ZACsI4c1ZACsI4c1ZACsI4c1ZABMm+OeKRSNRoOysjL947KyMmg0GgsmIiK6v9wzhdKhQwcUFRWhpKQEdXV1yM7ORnh4uKVjERHdN+6Zy4YVCgVGjRqFOXPmQKfToV+/fvD19TXpOmNiYky6fGNZQw5ryABYRw5ryABYRw5ryABYRw5ryACYNsc9c1KeiIgs6555y4uIiCyLhUJERLJgoRARkSzumZPylnLs2DHs3r0bY8aMsXQUsykuLsaFCxfQqVMng/Fjx47BxcUF3t7eZs9UUVEBAHB2djb7uq1BaWkp3N3dLZohNzcXZWVlePLJJwEA06ZN0/9chg0bhp49e1oy3n3lpZdegiRJjU6ztbWFt7c3nn/+eYSEhMi6XhbKXTh16hR2796NnJwceHp6okePHhbNU1FRAScnp1v+Aslt9erVGDJkyE3jKpUKq1evNtsHuIQQ2LRpE7777jvodDoAgI2NDf76179i4MCBZsmwbds2/P3vfwcA7N27F7169dJPW79+faP7yRTmz5+PDz74AADw4Ycf4vXXXzfLeq/35ZdfYsKECfrHtbW1mDt3Lq5evYply5aZrVBWrVrV5PRRo0aZJYclrVmz5pbTdDodfv/9dyQnJ2PBggWyrpeFYqSzZ89iz5492LNnD5ycnNC7d28IITBjxgyz5vj111+xfv16qNVqPPvss1iyZAkqKioghMCrr76KsLAwk2e4ePEi2rZte9N427Ztcf78eZOvv8H27dtx/PhxzJ07F56engCAc+fOISUlBV9//TWefvppk2fIzs7WF0paWppBoRw6dMhshXL9xZolJSVmWeeN6urqDI6SOnXqBCcnJzg5OeHq1atmy+Hn56f/+6ZNm/Dcc8+Zbd0NbnWEIISAJEn45JNPzJ6pgY2NDdq1a6c/kpQTC8VIkyZNQqdOnTBlyhT9Wzrbt283e45Vq1bhhRdeQHV1Nd577z1MnToVAQEB+OOPP7B48WKzFMqlS5duOa2mpsbk62+wc+dOvP322wZvc3l5eWHcuHGYPXu2WQrl+hfyG6/AN+cV+de/eJnrSPVGVVVVBo+vv49ew1tf5hAVFaX/+zfffGPw2FyaOkKwFo899pjsy2ShGOm1115DdnY23n33XXTu3Bl9+vQx6wtGg/r6enTu3BkAsHHjRgQEBAAA2rRpY7YMfn5+SE9Pv+kDUjt27DD436Gp1dfXN3rOxNnZGfX19WbJ0NQLuTlf2E+fPo3hw4dDCIGamhoMHz4cgHn/R9yxY8dGfy9++OEHdOjQweTrb4ylyvV+xUIxUo8ePdCjRw9cuXIF+/btw/bt21FRUYEVK1agR48e+hd5U7Ox+fPCPKVSaTDNXP94RowYgQ8//BC7d+/WF8h///tf1NXV4Y033jBLBuDaycW7mSanpl7Ia2trzZIBADZs2GC2dd3K8OHDMX/+fOzZswft27cHAJw8eRK1tbVm/b0gy+En5ZuhqqoKOTk5yM7OxjvvvGOWdQ4ePBj29vb6FzA7OzsAf76AffbZZ2bJAQCHDx/GmTNnAAC+vr545JFHzLZu4M99cSNL7Av6k6V/L64/f3H16lWDfyOWPn9xr2OhEBGRLPjBRiIikgULhYiIZMFCITKhjRs3IikpydIxiMyCV3kRyWD37t34+uuv8ccff8DBwQHt2rVDXFycpWMRmRULhaiZvv76a6SlpeF//ud/0LlzZ9ja2iIvLw+5ubn6K4yI7gcsFKJmqK6uxoYNG5CQkIBHH31UPx4eHo7w8HBs3LjRYP6FCxfi6NGjqKmpQbt27TBmzBj9N4seOHAAn376KcrKyuDg4IABAwbgmWeeQUVFBZYtW4Zjx45BkiT4+vpi5syZsLGxgVarxapVq3D06FHY29tjwIABeOqppwAAJ06cQEpKCoqKiqBUKtG3b1/952SITIGFQtQMv/76K2pra42+QWhYWBjGjh0LW1tbrFu3DklJSZg/fz4AYPny5Zg0aRICAwNRVVWlvyfX119/DY1Gg5SUFABAQUEBJEmCTqfDBx98gO7du2PixIkoKyvDrFmz4OPjg7CwMKSmpuKpp55CREQErly5gt9//900O4Ho/+NJeaJmqKyshJOTExQKhVHzR0dHw8HBAa1atcJzzz2H3377DdXV1QAAhUKBwsJCVFdXQ61W6+9CoFAocOHCBZSWlsLW1haBgYGQJAn//e9/UVFRgYEDB8LW1hZeXl7o378/srOzAVy7W0BxcTEqKipgb2+vv00PkanwCIWoGZycnFBZWYn6+vrblopOp8Nnn32GnJwcVFRU6D/NXVFRAZVKhddeew1btmzB+vXr0bZtWwwdOhQBAQF45plnsGnTJsyePRsAEBMTg9jYWJw/fx7l5eUYMWKEwToCAwMBAPHx8diwYQMmTZoET09PDBw4EN26dTPNjiACAEFEd+3SpUti2LBhYu/evY1O37Bhg1i8eLEQQoisrCwxceJEce7cOaHT6URVVZV47rnnRFFRkcFzamtrxVdffSXi4+NvWt5vv/0mRo8eLX7++Wdx/PhxMW7cuNtmrK+vF3v37hVDhgwRly9fvoutJDIO3/IiagaVSoVBgwZh5cqV+Omnn3D16lXU1dXh4MGDWLt2rcG8ly9fhq2tLdRqNa5evWpwr7G6ujrs2rUL1dXVsLW1hUql0h/B7N+/H8XFxRBCQKVSwcbGBpIkwd/fHw4ODkhLS0NNTY3+i5NOnDgB4Nrt/SsqKmBjYwOVSgXA8OaiRHLjW15EzfS3v/0NLi4u2LJlC5KTk2Fvbw8/Pz/ExcXh0KFD+vkiIyNx6NAhxMfHQ61WY/Dgwfj+++/103fu3IlVq1ZBp9PBx8cH48ePBwAUFRVh1apVqKiogKOjIx5//HH9DRffeustrFmzBv/85z9RV1cHHx8fDB48GACQl5eHNWvW4OrVq/Dw8MCECRNuukM1kZx4c0giIpIFj3+JiEgWLBQiIpIFC4WIiGTBQiEiIlmwUIiISBYsFCIikgULhYiIZMFCISIiWbBQiIhIFv8PTwDLHUqFEGYAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# data distribution per class\n",
    "\n",
    "print('Class D and B have the highest number of datapoints')\n",
    "\n",
    "df['Class'].value_counts().sort_index().plot(kind='bar', title='Number of data point per class',color='C1')\n",
    "plt.ylabel('Data Points')\n",
    "plt.xlabel('Classes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The architecture of the deep LTSM model is a two hidden layer network with 160 neurons in the first hidden layer and 200 neurons in the second hidden layer. \n",
    "\n",
    "Fortunately, the authors provided us with their model which we can use as inspiration to start off our search!\n",
    "\n",
    "The model .config() can be commented out for more information on the exact settings. For example, we can find out which dropout rate the authors used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-04 20:47:54.012577: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_3 (LSTM)               (None, None, 160)         116480    \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, None, 160)        640       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, None, 160)         0         \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 120)               134880    \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 120)              480       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 120)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 4)                 484       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 252,964\n",
      "Trainable params: 252,404\n",
      "Non-trainable params: 560\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "author_model = load_model('Model_clean_binary_cross_ICTAI_vehicle2_1')\n",
    "author_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comment out this line to obtain model setup\n",
    "# author_model.get_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original idea was to use the criteria mentioned on Brightspace however, the code didn't fully run therefore we created our own model so we could run it. Next to this, we will also apply a hyperparameter check and ablation study."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare features and classes\n",
    "X, y = pre_process_encoder(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partition the data with windows and assign it to train or test\n",
    "X_train, y_train, X_test,y_test = rnn_dimension(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the data (very important)\n",
    "X_train_scaled = normalizing(X_train)\n",
    "X_test_scaled = normalizing(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter\n",
    "Right now, the overall context of the data is pretty clear. It's time to start building models and fitting it to the data. \n",
    "\n",
    "The build_model() function is used to do hyperparameter checking. We'll also use keras tuner to automatically search for the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import keras packages\n",
    "from keras.layers import Dense, Dropout, LSTM, Activation, Flatten\n",
    "from keras_tuner.tuners import RandomSearch\n",
    "from kerastuner.engine.hyperparameters import HyperParameters\n",
    "\n",
    "# import other packages\n",
    "\n",
    "# build_model is a function that is defined underneath here right?\n",
    "# import build_model \n",
    "import pathlib\n",
    "from keras import callbacks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create validation set for hyperparameter checking\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test_scaled, y_test, test_size=0.7, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate hyperparameter object\n",
    "# this will be passed to the build_model() function\n",
    "hp = HyperParameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model\n",
    "def build_model(hp):\n",
    "    \"\"\" \n",
    "    Build model for dynamic hyper parameter training.\n",
    "    input: hp \"object\" (HyperParameters() from kerastuner.engine.hyperparameters)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create sequential model\n",
    "    model = Sequential()\n",
    "\n",
    "    # HyperParameters\n",
    "    activations = hp.Choice(\"activation\", [\"relu\", \"tanh\"])\n",
    "    dropouts    = hp.Float(\"dropout\", min_value=0.3, max_value=0.6, step=0.05)\n",
    "    optimizers  = hp.Choice(\"optimizer\", [\"adam\", \"sgd\"])\n",
    "    units       = hp.Int(\"units\", min_value=140, max_value=220, step=10)\n",
    "\n",
    "    # first LSTM layer\n",
    "    model.add(LSTM(\n",
    "        units=units, \n",
    "        input_dim=X_train.shape[2], \n",
    "        activation=activations, \n",
    "        return_sequences=True))\n",
    "\n",
    "    # intermediate layers\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Dropout(dropouts))\n",
    "\n",
    "    # 2nd LSTM layer\n",
    "    model.add(LSTM(\n",
    "        units=units, \n",
    "        input_shape=(X_train.shape[1],X_train.shape[2]), \n",
    "        activation= activations, \n",
    "        return_sequences=False))\n",
    "\n",
    "    # intermediate layers\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Dropout(dropouts))\n",
    "\n",
    "    # output layer\n",
    "    model.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "\n",
    "    # compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizers, metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_history = []\n",
    "bias_history = []\n",
    "class MyCallback(callbacks.Callback):\n",
    "    def on_batch_end(self, batch, logs):\n",
    "        weight, bias = model.get_weights()\n",
    "        B = bias[0]\n",
    "        W = weight[0][0]\n",
    "        weight_history.append(W)\n",
    "        bias_history.append(B)\n",
    "callback = MyCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_logger = callbacks.CSVLogger('training.csv', append=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify path to save the search\n",
    "path_save = pathlib.Path(str(pathlib.Path().parent.resolve()) + \"/models\")\n",
    "\n",
    "# change project name\n",
    "project_name = \"search1\"\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective = \"val_accuracy\",\n",
    "    max_trials = 2,\n",
    "    executions_per_trial = 1,\n",
    "    directory = path_save,\n",
    "    project_name= project_name,\n",
    "    overwrite = True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 Complete [00h 00m 19s]\n",
      "val_accuracy: 0.7721280455589294\n",
      "\n",
      "Best val_accuracy So Far: 0.7777777910232544\n",
      "Total elapsed time: 00h 00m 40s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(x=X_train_scaled, \n",
    "             y=y_train,\n",
    "             epochs=2, \n",
    "             batch_size=21, \n",
    "             validation_data=(X_val, y_val),\n",
    "            #  callbacks=[tf.keras.callbacks.TensorBoard(pathlib.Path(r'C:\\Users\\dicis\\Desktop\\models'))]\n",
    "             callbacks=[csv_logger]\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.sequential.Sequential at 0x19ac7bee0>,\n",
       " <keras.engine.sequential.Sequential at 0x19ce67ac0>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner.get_best_models(num_models=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trial_id</th>\n",
       "      <th>hyperparameters</th>\n",
       "      <th>metrics</th>\n",
       "      <th>score</th>\n",
       "      <th>best_step</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>space</th>\n",
       "      <td>0</td>\n",
       "      <td>[{'class_name': 'Choice', 'config': {'name': '...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0</td>\n",
       "      <td>COMPLETED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>values</th>\n",
       "      <td>0</td>\n",
       "      <td>{'activation2': 'relu', 'dropout2': 0.44999999...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0</td>\n",
       "      <td>COMPLETED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metrics</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'loss': {'direction': 'min', 'observations': ...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0</td>\n",
       "      <td>COMPLETED</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         trial_id                                    hyperparameters  \\\n",
       "space           0  [{'class_name': 'Choice', 'config': {'name': '...   \n",
       "values          0  {'activation2': 'relu', 'dropout2': 0.44999999...   \n",
       "metrics         0                                                NaN   \n",
       "\n",
       "                                                   metrics     score  \\\n",
       "space                                                  NaN  0.777778   \n",
       "values                                                 NaN  0.777778   \n",
       "metrics  {'loss': {'direction': 'min', 'observations': ...  0.777778   \n",
       "\n",
       "         best_step     status  \n",
       "space            0  COMPLETED  \n",
       "values           0  COMPLETED  \n",
       "metrics          0  COMPLETED  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_json('./models/search1/trial_0/trial.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation2': 'relu',\n",
       " 'dropout2': 0.449999999999999,\n",
       " 'optimizer': 'sgd',\n",
       " 'units': 220}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_json('./models/search1/trial_0/trial.json')['hyperparameters'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': {'direction': 'min',\n",
       "  'observations': [{'value': [1.011610746383667], 'step': 0}]},\n",
       " 'accuracy': {'direction': 'max',\n",
       "  'observations': [{'value': [0.629762589931488], 'step': 0}]},\n",
       " 'val_loss': {'direction': 'min',\n",
       "  'observations': [{'value': [0.650487720966339], 'step': 0}]},\n",
       " 'val_accuracy': {'direction': 'max',\n",
       "  'observations': [{'value': [0.7777777910232541], 'step': 0}]}}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_json('./models/search1/trial_0/trial.json')['metrics'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RandomSearch' object has no attribute 'trials'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/gn/zs8gg_z13yl9cprztlvpc9gc0000gq/T/ipykernel_48459/405684166.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'RandomSearch' object has no attribute 'trials'"
     ]
    }
   ],
   "source": [
    "tuner.trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.momentum\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.momentum\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.momentum\n"
     ]
    }
   ],
   "source": [
    "a_model = tuner.get_best_models(num_models=5)[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = tuner.get_best_models(num_models=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "478/478 [==============================] - 28s 53ms/step - loss: 0.4009 - accuracy: 0.8554\n",
      "Epoch 2/6\n",
      "478/478 [==============================] - 26s 54ms/step - loss: 0.3322 - accuracy: 0.8790\n",
      "Epoch 3/6\n",
      "478/478 [==============================] - 25s 53ms/step - loss: 0.2800 - accuracy: 0.9007\n",
      "Epoch 4/6\n",
      "478/478 [==============================] - 26s 55ms/step - loss: 0.2414 - accuracy: 0.9147\n",
      "Epoch 5/6\n",
      "478/478 [==============================] - 25s 52ms/step - loss: 0.2192 - accuracy: 0.9258\n",
      "Epoch 6/6\n",
      "478/478 [==============================] - 24s 50ms/step - loss: 0.1957 - accuracy: 0.9330\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4f95966fd0>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.fit(X_train_scaled, y_train, epochs=6, batch_size=21, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x576 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "epochs = np.arange(1, len(best_model.history.history['loss']) + 1)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 8))\n",
    "fig.suptitle('Train scores')\n",
    "\n",
    "ax1.plot(epochs, best_model.history.history['loss'], 'o-')\n",
    "ax1.set_ylabel('train_loss')\n",
    "\n",
    "ax2.plot(epochs, best_model.history.history['accuracy'], '.-')\n",
    "ax2.set_xlabel('epochs')\n",
    "ax2.set_ylabel('accuracy')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 01:58:02.794878: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./best_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./best_model/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f4ff44f3340> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f4fadd0a640> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "best_model.save('./best_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_model = load_model('./best_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproducing fig 9\n",
    "We are starting with reproducing figure 9, taken from the original paper:\n",
    "\n",
    "<img src=\"original_figure9.png\" alt=\"Graph showing 4 different classfiers' robustness to noise. LSTM is clearly the most robust\" style=\"width: 500px;\"/>\n",
    "\n",
    "To do this, we first need the 4 different models shown (LSTM, FCNN, DecisionTree, RandomForest) in the graph. We use the LSTM that we found through the hyper parameter tuning above. The design of the FCNN that was likely used for this graph can be found in the code provided by the original author. The DecisionTree and RandomForest can be imported straight from keras. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start, we prepare the data again. This is done to keep everythhing contained a bit, and not use data that was prepared in a different part of the code. We load the data, one hot encode the labels and create train/test sets. Lastly, we scale the training and testing inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a clean copy of the data to make sure previous cells did not do something unexpected to the data\n",
    "# As in the original paper, these model will be trained on the data without 'windows' (ie group of consecutive data points)\n",
    "# This data will be marked as _nw (No Window) I do agree the names are getting a little long\n",
    "\n",
    "df = pd.read_csv('./Data/korea_vehicledata.csv')\n",
    "X_nw, y_nw = pre_process_encoder(df)\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_nw)\n",
    "y_ints = encoder.transform(y_nw)  # A, B, C, ... --> 1, 2, 3, ...\n",
    "y_dummy_nw = np_utils.to_categorical(y_ints)\n",
    "X_train_nw, X_test_nw, y_train_nw, y_test_nw =train_test_split(X_nw, y_dummy_nw, train_size=0.85)\n",
    "X_train_scaled_nw = normalizing_2d(X_train_nw)\n",
    "X_test_scaled_nw = normalizing_2d(X_test_nw)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import the layers we need (some were already imported but for me it is nice to be able to run just this part - hence I import them again).\n",
    "We also import some functions and classifiers from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Flatten, Dense\n",
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by creating the FCNN, by adapting (but mainly copying) the code from the author and fitting it on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "803/803 [==============================] - 4s 3ms/step - loss: 1.2436 - accuracy: 0.5493\n",
      "Epoch 2/10\n",
      "803/803 [==============================] - 3s 4ms/step - loss: 0.6408 - accuracy: 0.7614\n",
      "Epoch 3/10\n",
      "803/803 [==============================] - 3s 4ms/step - loss: 0.4765 - accuracy: 0.8243\n",
      "Epoch 4/10\n",
      "803/803 [==============================] - 3s 4ms/step - loss: 0.3900 - accuracy: 0.8563\n",
      "Epoch 5/10\n",
      "803/803 [==============================] - 3s 4ms/step - loss: 0.3417 - accuracy: 0.8751\n",
      "Epoch 6/10\n",
      "803/803 [==============================] - 3s 4ms/step - loss: 0.3031 - accuracy: 0.8900\n",
      "Epoch 7/10\n",
      "803/803 [==============================] - 3s 4ms/step - loss: 0.2782 - accuracy: 0.8988\n",
      "Epoch 8/10\n",
      "803/803 [==============================] - 3s 4ms/step - loss: 0.2544 - accuracy: 0.9077\n",
      "Epoch 9/10\n",
      "803/803 [==============================] - 3s 4ms/step - loss: 0.2394 - accuracy: 0.9132\n",
      "Epoch 10/10\n",
      "803/803 [==============================] - 3s 3ms/step - loss: 0.2235 - accuracy: 0.9187\n"
     ]
    }
   ],
   "source": [
    "FCNN_model = Sequential()\n",
    "# FCNN_model.add(Flatten())  # Flatten the input data so it can be passed through the dense layer\n",
    "FCNN_model.add(Dense(160, input_dim=X_train_scaled_nw.shape[1], activation='relu'))\n",
    "FCNN_model.add(layers.BatchNormalization())\n",
    "FCNN_model.add(layers.Dropout(0.5))\n",
    "FCNN_model.add(Dense(120, activation='relu'))\n",
    "FCNN_model.add(layers.BatchNormalization())\n",
    "FCNN_model.add(Dense(y_test_nw.shape[1], activation='softmax'))\n",
    "# FCNN_model.add(Dense(1,activation='sigmoid'))\n",
    "# FCNN_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "FCNN_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "with tf.device('/GPU:0'):\n",
    "    FCNN_history = FCNN_model.fit(X_train_scaled_nw, y_train_nw, epochs=10,batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also create and fit the DecisionTree and RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=20)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DT_model = DecisionTreeClassifier()\n",
    "DT_model.fit(X_train_scaled_nw, y_train_nw)\n",
    "\n",
    "RF_model = RandomForestClassifier(n_estimators=20)  # original paper uses 20 estimators\n",
    "RF_model.fit(X_train_scaled_nw, y_train_nw)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have the four models, but the LSTM and FCNN are not very well trained yet. Their accuracy is around 90% while the paper is closer to 100%. To fix this, we let them train for a bit longer. I suggest not to use this and just load the model:)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "803/803 [==============================] - 3s 3ms/step - loss: 0.2114 - accuracy: 0.9239\n",
      "Epoch 2/150\n",
      "803/803 [==============================] - 3s 3ms/step - loss: 0.1998 - accuracy: 0.9288\n",
      "Epoch 3/150\n",
      "803/803 [==============================] - 3s 4ms/step - loss: 0.1891 - accuracy: 0.9318\n",
      "Epoch 4/150\n",
      "803/803 [==============================] - 3s 4ms/step - loss: 0.1819 - accuracy: 0.9347\n",
      "Epoch 5/150\n",
      "803/803 [==============================] - 3s 4ms/step - loss: 0.1745 - accuracy: 0.9386\n",
      "Epoch 6/150\n",
      "803/803 [==============================] - 3s 4ms/step - loss: 0.1677 - accuracy: 0.9400\n",
      "Epoch 7/150\n",
      "803/803 [==============================] - 3s 3ms/step - loss: 0.1610 - accuracy: 0.9420\n",
      "Epoch 8/150\n",
      "803/803 [==============================] - 3s 3ms/step - loss: 0.1548 - accuracy: 0.9446\n",
      "Epoch 9/150\n",
      "803/803 [==============================] - 3s 3ms/step - loss: 0.1524 - accuracy: 0.9448\n",
      "Epoch 10/150\n",
      "803/803 [==============================] - 3s 4ms/step - loss: 0.1464 - accuracy: 0.9479\n",
      "Epoch 11/150\n",
      "803/803 [==============================] - 3s 4ms/step - loss: 0.1447 - accuracy: 0.9490\n",
      "Epoch 12/150\n",
      "803/803 [==============================] - 3s 4ms/step - loss: 0.1398 - accuracy: 0.9501\n",
      "Epoch 13/150\n",
      "803/803 [==============================] - 3s 4ms/step - loss: 0.1357 - accuracy: 0.9514\n",
      "Epoch 14/150\n",
      "803/803 [==============================] - 3s 4ms/step - loss: 0.1332 - accuracy: 0.9527\n",
      "Epoch 15/150\n",
      "803/803 [==============================] - 3s 4ms/step - loss: 0.1323 - accuracy: 0.9534\n",
      "Epoch 16/150\n",
      "803/803 [==============================] - 3s 3ms/step - loss: 0.1300 - accuracy: 0.9543\n",
      "Epoch 17/150\n",
      "803/803 [==============================] - 3s 3ms/step - loss: 0.1228 - accuracy: 0.9569\n",
      "Epoch 18/150\n",
      "803/803 [==============================] - 4s 5ms/step - loss: 0.1218 - accuracy: 0.9563\n",
      "Epoch 19/150\n",
      "803/803 [==============================] - 4s 4ms/step - loss: 0.1213 - accuracy: 0.9568\n",
      "Epoch 20/150\n",
      "803/803 [==============================] - 4s 4ms/step - loss: 0.1164 - accuracy: 0.9587\n",
      "Epoch 21/150\n",
      "803/803 [==============================] - 6s 7ms/step - loss: 0.1169 - accuracy: 0.9581\n",
      "Epoch 22/150\n",
      "803/803 [==============================] - 4s 6ms/step - loss: 0.1132 - accuracy: 0.9601\n",
      "Epoch 23/150\n",
      "803/803 [==============================] - 4s 4ms/step - loss: 0.1090 - accuracy: 0.9621\n",
      "Epoch 24/150\n",
      "803/803 [==============================] - 6s 7ms/step - loss: 0.1079 - accuracy: 0.9622\n",
      "Epoch 25/150\n",
      "803/803 [==============================] - 5s 7ms/step - loss: 0.1081 - accuracy: 0.9623\n",
      "Epoch 26/150\n",
      "803/803 [==============================] - 3s 4ms/step - loss: 0.1052 - accuracy: 0.9632\n",
      "Epoch 27/150\n",
      "803/803 [==============================] - 3s 3ms/step - loss: 0.1047 - accuracy: 0.9627\n",
      "Epoch 28/150\n",
      "803/803 [==============================] - 3s 4ms/step - loss: 0.1039 - accuracy: 0.9635\n",
      "Epoch 29/150\n",
      "803/803 [==============================] - 4s 5ms/step - loss: 0.0980 - accuracy: 0.9655\n",
      "Epoch 30/150\n",
      "803/803 [==============================] - 3s 3ms/step - loss: 0.1000 - accuracy: 0.9649\n",
      "Epoch 31/150\n",
      "803/803 [==============================] - 3s 4ms/step - loss: 0.0948 - accuracy: 0.9662\n",
      "Epoch 32/150\n",
      "803/803 [==============================] - 4s 5ms/step - loss: 0.0922 - accuracy: 0.9675\n",
      "Epoch 33/150\n",
      "803/803 [==============================] - 4s 5ms/step - loss: 0.0970 - accuracy: 0.9664\n",
      "Epoch 34/150\n",
      "803/803 [==============================] - 5s 6ms/step - loss: 0.0924 - accuracy: 0.9668\n",
      "Epoch 35/150\n",
      "803/803 [==============================] - 4s 4ms/step - loss: 0.0907 - accuracy: 0.9678\n",
      "Epoch 36/150\n",
      "803/803 [==============================] - 4s 5ms/step - loss: 0.0909 - accuracy: 0.9677\n",
      "Epoch 37/150\n",
      "803/803 [==============================] - 4s 5ms/step - loss: 0.0914 - accuracy: 0.9684\n",
      "Epoch 38/150\n",
      "803/803 [==============================] - 6s 7ms/step - loss: 0.0895 - accuracy: 0.9694\n",
      "Epoch 39/150\n",
      "803/803 [==============================] - 4s 5ms/step - loss: 0.0896 - accuracy: 0.9689\n",
      "Epoch 40/150\n",
      "803/803 [==============================] - 3s 4ms/step - loss: 0.0867 - accuracy: 0.9698\n",
      "Epoch 41/150\n",
      "803/803 [==============================] - 3s 4ms/step - loss: 0.0837 - accuracy: 0.9704\n",
      "Epoch 42/150\n",
      "803/803 [==============================] - 4s 5ms/step - loss: 0.0851 - accuracy: 0.9704\n",
      "Epoch 43/150\n",
      "803/803 [==============================] - 6s 8ms/step - loss: 0.0840 - accuracy: 0.9708\n",
      "Epoch 44/150\n",
      "803/803 [==============================] - 4s 5ms/step - loss: 0.0799 - accuracy: 0.9719\n",
      "Epoch 45/150\n",
      "803/803 [==============================] - 3s 3ms/step - loss: 0.0860 - accuracy: 0.9702\n",
      "Epoch 46/150\n",
      "803/803 [==============================] - 4s 4ms/step - loss: 0.0800 - accuracy: 0.9718\n",
      "Epoch 47/150\n",
      "803/803 [==============================] - 3s 4ms/step - loss: 0.0808 - accuracy: 0.9721\n",
      "Epoch 48/150\n",
      "803/803 [==============================] - 3s 4ms/step - loss: 0.0797 - accuracy: 0.9724\n",
      "Epoch 49/150\n",
      "803/803 [==============================] - 4s 5ms/step - loss: 0.0809 - accuracy: 0.9719\n",
      "Epoch 50/150\n",
      "803/803 [==============================] - 5s 7ms/step - loss: 0.0811 - accuracy: 0.9723\n",
      "Epoch 51/150\n",
      "803/803 [==============================] - 3s 4ms/step - loss: 0.0771 - accuracy: 0.9728\n",
      "Epoch 52/150\n",
      "803/803 [==============================] - 3s 4ms/step - loss: 0.0780 - accuracy: 0.9728\n",
      "Epoch 53/150\n",
      "803/803 [==============================] - 3s 4ms/step - loss: 0.0789 - accuracy: 0.9720\n",
      "Epoch 54/150\n",
      "803/803 [==============================] - 3s 4ms/step - loss: 0.0795 - accuracy: 0.9725\n",
      "Epoch 55/150\n",
      "803/803 [==============================] - 3s 4ms/step - loss: 0.0764 - accuracy: 0.9739\n",
      "Epoch 56/150\n",
      "803/803 [==============================] - 4s 5ms/step - loss: 0.0772 - accuracy: 0.9732\n",
      "Epoch 57/150\n",
      "803/803 [==============================] - 4s 5ms/step - loss: 0.0756 - accuracy: 0.9737\n",
      "Epoch 58/150\n",
      "803/803 [==============================] - 3s 4ms/step - loss: 0.0759 - accuracy: 0.9731\n",
      "Epoch 59/150\n",
      "803/803 [==============================] - 3s 4ms/step - loss: 0.0726 - accuracy: 0.9746\n",
      "Epoch 60/150\n",
      "803/803 [==============================] - 3s 4ms/step - loss: 0.0741 - accuracy: 0.9739\n",
      "Epoch 61/150\n",
      "803/803 [==============================] - 3s 4ms/step - loss: 0.0733 - accuracy: 0.9751\n",
      "Epoch 62/150\n",
      "803/803 [==============================] - 3s 4ms/step - loss: 0.0730 - accuracy: 0.9741\n",
      "Epoch 63/150\n",
      "803/803 [==============================] - 3s 4ms/step - loss: 0.0790 - accuracy: 0.9727\n",
      "Epoch 64/150\n",
      "803/803 [==============================] - 3s 4ms/step - loss: 0.0742 - accuracy: 0.9741\n",
      "Epoch 65/150\n",
      "803/803 [==============================] - 3s 4ms/step - loss: 0.0716 - accuracy: 0.9747\n",
      "Epoch 66/150\n",
      "803/803 [==============================] - 3s 4ms/step - loss: 0.0704 - accuracy: 0.9756\n",
      "Epoch 67/150\n",
      "803/803 [==============================] - 2s 3ms/step - loss: 0.0659 - accuracy: 0.9766\n",
      "Epoch 68/150\n",
      "803/803 [==============================] - 2s 3ms/step - loss: 0.0696 - accuracy: 0.9759\n",
      "Epoch 69/150\n",
      "803/803 [==============================] - 2s 2ms/step - loss: 0.0690 - accuracy: 0.9757\n",
      "Epoch 70/150\n",
      "803/803 [==============================] - 2s 2ms/step - loss: 0.0704 - accuracy: 0.9756\n",
      "Epoch 71/150\n",
      "803/803 [==============================] - 3s 3ms/step - loss: 0.0679 - accuracy: 0.9762\n",
      "Epoch 72/150\n",
      "803/803 [==============================] - 3s 4ms/step - loss: 0.0684 - accuracy: 0.9761\n",
      "Epoch 73/150\n",
      "803/803 [==============================] - 3s 4ms/step - loss: 0.0697 - accuracy: 0.9759\n",
      "Epoch 74/150\n",
      "803/803 [==============================] - 3s 4ms/step - loss: 0.0681 - accuracy: 0.9760\n",
      "Epoch 75/150\n",
      "803/803 [==============================] - 3s 4ms/step - loss: 0.0667 - accuracy: 0.9767\n",
      "Epoch 76/150\n",
      "803/803 [==============================] - 3s 4ms/step - loss: 0.0670 - accuracy: 0.9765\n",
      "Epoch 77/150\n",
      "803/803 [==============================] - 3s 4ms/step - loss: 0.0658 - accuracy: 0.9762\n",
      "Epoch 78/150\n",
      "803/803 [==============================] - 3s 4ms/step - loss: 0.0673 - accuracy: 0.9767\n",
      "Epoch 79/150\n",
      "803/803 [==============================] - 3s 4ms/step - loss: 0.0640 - accuracy: 0.9778\n",
      "Epoch 80/150\n",
      "803/803 [==============================] - 3s 4ms/step - loss: 0.0633 - accuracy: 0.9777\n",
      "Epoch 81/150\n",
      "803/803 [==============================] - 3s 4ms/step - loss: 0.0634 - accuracy: 0.9775\n",
      "Epoch 82/150\n",
      "803/803 [==============================] - 3s 4ms/step - loss: 0.0642 - accuracy: 0.9776\n",
      "Epoch 83/150\n",
      "803/803 [==============================] - 4s 5ms/step - loss: 0.0623 - accuracy: 0.9785\n",
      "Epoch 84/150\n",
      "803/803 [==============================] - 3s 4ms/step - loss: 0.0640 - accuracy: 0.9779\n",
      "Epoch 85/150\n",
      "803/803 [==============================] - 3s 3ms/step - loss: 0.0635 - accuracy: 0.9780\n",
      "Epoch 86/150\n",
      "803/803 [==============================] - 3s 3ms/step - loss: 0.0650 - accuracy: 0.9771\n",
      "Epoch 87/150\n",
      "803/803 [==============================] - 3s 3ms/step - loss: 0.0618 - accuracy: 0.9792\n",
      "Epoch 88/150\n",
      "803/803 [==============================] - 3s 4ms/step - loss: 0.0623 - accuracy: 0.9785\n",
      "Epoch 89/150\n",
      "803/803 [==============================] - 4s 4ms/step - loss: 0.0598 - accuracy: 0.9793\n",
      "Epoch 90/150\n",
      "803/803 [==============================] - 3s 4ms/step - loss: 0.0625 - accuracy: 0.9782\n",
      "Epoch 91/150\n",
      "803/803 [==============================] - 3s 4ms/step - loss: 0.0620 - accuracy: 0.9788\n",
      "Epoch 92/150\n",
      "803/803 [==============================] - 3s 4ms/step - loss: 0.0584 - accuracy: 0.9797\n",
      "Epoch 93/150\n",
      "803/803 [==============================] - 3s 3ms/step - loss: 0.0598 - accuracy: 0.9796\n",
      "Epoch 94/150\n",
      "803/803 [==============================] - 3s 4ms/step - loss: 0.0607 - accuracy: 0.9787\n",
      "Epoch 95/150\n",
      "803/803 [==============================] - 3s 3ms/step - loss: 0.0595 - accuracy: 0.9795\n",
      "Epoch 96/150\n",
      "803/803 [==============================] - 3s 3ms/step - loss: 0.0608 - accuracy: 0.9792\n",
      "Epoch 97/150\n",
      "803/803 [==============================] - 3s 3ms/step - loss: 0.0590 - accuracy: 0.9799\n",
      "Epoch 98/150\n",
      "803/803 [==============================] - 3s 3ms/step - loss: 0.0594 - accuracy: 0.9797\n",
      "Epoch 99/150\n",
      "803/803 [==============================] - 3s 3ms/step - loss: 0.0577 - accuracy: 0.9800\n",
      "Epoch 100/150\n",
      "803/803 [==============================] - 3s 3ms/step - loss: 0.0569 - accuracy: 0.9807\n",
      "Epoch 101/150\n",
      "803/803 [==============================] - 3s 3ms/step - loss: 0.0572 - accuracy: 0.9800\n",
      "Epoch 102/150\n",
      "803/803 [==============================] - 3s 3ms/step - loss: 0.0559 - accuracy: 0.9810\n",
      "Epoch 103/150\n",
      "803/803 [==============================] - 3s 3ms/step - loss: 0.0580 - accuracy: 0.9803\n",
      "Epoch 104/150\n",
      "803/803 [==============================] - 2s 3ms/step - loss: 0.0573 - accuracy: 0.9806\n",
      "Epoch 105/150\n",
      "803/803 [==============================] - 2s 3ms/step - loss: 0.0559 - accuracy: 0.9806\n",
      "Epoch 106/150\n",
      "803/803 [==============================] - 2s 2ms/step - loss: 0.0532 - accuracy: 0.9815\n",
      "Epoch 107/150\n",
      "803/803 [==============================] - 2s 3ms/step - loss: 0.0554 - accuracy: 0.9808\n",
      "Epoch 108/150\n",
      "803/803 [==============================] - 2s 2ms/step - loss: 0.0545 - accuracy: 0.9806\n",
      "Epoch 109/150\n",
      "803/803 [==============================] - 2s 3ms/step - loss: 0.0534 - accuracy: 0.9810\n",
      "Epoch 110/150\n",
      "803/803 [==============================] - 2s 3ms/step - loss: 0.0552 - accuracy: 0.9808\n",
      "Epoch 111/150\n",
      "803/803 [==============================] - 2s 3ms/step - loss: 0.0539 - accuracy: 0.9813\n",
      "Epoch 112/150\n",
      "803/803 [==============================] - 2s 2ms/step - loss: 0.0521 - accuracy: 0.9819\n",
      "Epoch 113/150\n",
      "803/803 [==============================] - 2s 2ms/step - loss: 0.0535 - accuracy: 0.9816\n",
      "Epoch 114/150\n",
      "803/803 [==============================] - 2s 2ms/step - loss: 0.0544 - accuracy: 0.9808\n",
      "Epoch 115/150\n",
      "803/803 [==============================] - 2s 2ms/step - loss: 0.0513 - accuracy: 0.9817\n",
      "Epoch 116/150\n",
      "803/803 [==============================] - 2s 2ms/step - loss: 0.0522 - accuracy: 0.9818\n",
      "Epoch 117/150\n",
      "803/803 [==============================] - 2s 2ms/step - loss: 0.0540 - accuracy: 0.9818\n",
      "Epoch 118/150\n",
      "803/803 [==============================] - 2s 3ms/step - loss: 0.0525 - accuracy: 0.9812\n",
      "Epoch 119/150\n",
      "803/803 [==============================] - 2s 2ms/step - loss: 0.0518 - accuracy: 0.9817\n",
      "Epoch 120/150\n",
      "803/803 [==============================] - 2s 2ms/step - loss: 0.0506 - accuracy: 0.9828\n",
      "Epoch 121/150\n",
      "803/803 [==============================] - 2s 2ms/step - loss: 0.0530 - accuracy: 0.9809\n",
      "Epoch 122/150\n",
      "803/803 [==============================] - 2s 2ms/step - loss: 0.0506 - accuracy: 0.9821\n",
      "Epoch 123/150\n",
      "803/803 [==============================] - 2s 2ms/step - loss: 0.0476 - accuracy: 0.9837\n",
      "Epoch 124/150\n",
      "803/803 [==============================] - 2s 2ms/step - loss: 0.0507 - accuracy: 0.9826\n",
      "Epoch 125/150\n",
      "803/803 [==============================] - 2s 3ms/step - loss: 0.0522 - accuracy: 0.9816\n",
      "Epoch 126/150\n",
      "803/803 [==============================] - 2s 3ms/step - loss: 0.0509 - accuracy: 0.9825\n",
      "Epoch 127/150\n",
      "803/803 [==============================] - 2s 3ms/step - loss: 0.0528 - accuracy: 0.9820\n",
      "Epoch 128/150\n",
      "803/803 [==============================] - 2s 3ms/step - loss: 0.0520 - accuracy: 0.9818\n",
      "Epoch 129/150\n",
      "803/803 [==============================] - 2s 3ms/step - loss: 0.0486 - accuracy: 0.9831\n",
      "Epoch 130/150\n",
      "803/803 [==============================] - 2s 2ms/step - loss: 0.0483 - accuracy: 0.9835\n",
      "Epoch 131/150\n",
      "803/803 [==============================] - 2s 2ms/step - loss: 0.0501 - accuracy: 0.9828\n",
      "Epoch 132/150\n",
      "803/803 [==============================] - 2s 2ms/step - loss: 0.0506 - accuracy: 0.9830\n",
      "Epoch 133/150\n",
      "803/803 [==============================] - 2s 2ms/step - loss: 0.0490 - accuracy: 0.9834\n",
      "Epoch 134/150\n",
      "803/803 [==============================] - 2s 2ms/step - loss: 0.0491 - accuracy: 0.9827\n",
      "Epoch 135/150\n",
      "803/803 [==============================] - 2s 2ms/step - loss: 0.0495 - accuracy: 0.9831\n",
      "Epoch 136/150\n",
      "803/803 [==============================] - 2s 2ms/step - loss: 0.0477 - accuracy: 0.9835\n",
      "Epoch 137/150\n",
      "803/803 [==============================] - 2s 2ms/step - loss: 0.0478 - accuracy: 0.9835\n",
      "Epoch 138/150\n",
      "803/803 [==============================] - 2s 2ms/step - loss: 0.0473 - accuracy: 0.9837\n",
      "Epoch 139/150\n",
      "803/803 [==============================] - 2s 3ms/step - loss: 0.0505 - accuracy: 0.9825\n",
      "Epoch 140/150\n",
      "803/803 [==============================] - 2s 2ms/step - loss: 0.0473 - accuracy: 0.9833\n",
      "Epoch 141/150\n",
      "803/803 [==============================] - 2s 2ms/step - loss: 0.0459 - accuracy: 0.9840\n",
      "Epoch 142/150\n",
      "803/803 [==============================] - 2s 2ms/step - loss: 0.0466 - accuracy: 0.9838\n",
      "Epoch 143/150\n",
      "803/803 [==============================] - 2s 3ms/step - loss: 0.0484 - accuracy: 0.9834\n",
      "Epoch 144/150\n",
      "803/803 [==============================] - 2s 3ms/step - loss: 0.0468 - accuracy: 0.9841\n",
      "Epoch 145/150\n",
      "803/803 [==============================] - 2s 3ms/step - loss: 0.0471 - accuracy: 0.9834\n",
      "Epoch 146/150\n",
      "803/803 [==============================] - 2s 3ms/step - loss: 0.0498 - accuracy: 0.9831\n",
      "Epoch 147/150\n",
      "803/803 [==============================] - 2s 3ms/step - loss: 0.0462 - accuracy: 0.9837\n",
      "Epoch 148/150\n",
      "803/803 [==============================] - 2s 2ms/step - loss: 0.0453 - accuracy: 0.9845\n",
      "Epoch 149/150\n",
      "803/803 [==============================] - 2s 2ms/step - loss: 0.0469 - accuracy: 0.9840\n",
      "Epoch 150/150\n",
      "803/803 [==============================] - 2s 2ms/step - loss: 0.0468 - accuracy: 0.9842\n",
      "INFO:tensorflow:Assets written to: ./FCNN_model_reproduce/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./FCNN_model_reproduce/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "478/478 [==============================] - 18s 31ms/step - loss: 0.1783 - accuracy: 0.9377\n",
      "Epoch 2/150\n",
      "478/478 [==============================] - 18s 37ms/step - loss: 0.1570 - accuracy: 0.9471\n",
      "Epoch 3/150\n",
      "478/478 [==============================] - 27s 57ms/step - loss: 0.1445 - accuracy: 0.9509\n",
      "Epoch 4/150\n",
      "478/478 [==============================] - 29s 62ms/step - loss: 0.1342 - accuracy: 0.9532\n",
      "Epoch 5/150\n",
      "478/478 [==============================] - 33s 69ms/step - loss: 0.1186 - accuracy: 0.9602\n",
      "Epoch 6/150\n",
      "478/478 [==============================] - 23s 48ms/step - loss: 0.1125 - accuracy: 0.9640\n",
      "Epoch 7/150\n",
      "478/478 [==============================] - 22s 46ms/step - loss: 0.1093 - accuracy: 0.9621\n",
      "Epoch 8/150\n",
      "478/478 [==============================] - 21s 44ms/step - loss: 0.0946 - accuracy: 0.9688\n",
      "Epoch 9/150\n",
      "478/478 [==============================] - 22s 46ms/step - loss: 0.0877 - accuracy: 0.9713\n",
      "Epoch 10/150\n",
      "478/478 [==============================] - 28s 60ms/step - loss: 0.0841 - accuracy: 0.9736\n",
      "Epoch 11/150\n",
      "478/478 [==============================] - 27s 57ms/step - loss: 0.0939 - accuracy: 0.9698\n",
      "Epoch 12/150\n",
      "478/478 [==============================] - 30s 63ms/step - loss: 0.0697 - accuracy: 0.9787\n",
      "Epoch 13/150\n",
      "478/478 [==============================] - 27s 56ms/step - loss: 0.0603 - accuracy: 0.9806\n",
      "Epoch 14/150\n",
      "478/478 [==============================] - 28s 58ms/step - loss: 0.0849 - accuracy: 0.9739\n",
      "Epoch 15/150\n",
      "478/478 [==============================] - 34s 70ms/step - loss: 0.0537 - accuracy: 0.9830\n",
      "Epoch 16/150\n",
      "478/478 [==============================] - 32s 67ms/step - loss: 0.0563 - accuracy: 0.9821\n",
      "Epoch 17/150\n",
      "478/478 [==============================] - 26s 53ms/step - loss: 0.0559 - accuracy: 0.9836\n",
      "Epoch 18/150\n",
      "478/478 [==============================] - 24s 50ms/step - loss: 0.0617 - accuracy: 0.9815\n",
      "Epoch 19/150\n",
      "478/478 [==============================] - 22s 47ms/step - loss: 0.0430 - accuracy: 0.9866\n",
      "Epoch 20/150\n",
      "478/478 [==============================] - 24s 49ms/step - loss: 0.0468 - accuracy: 0.9866\n",
      "Epoch 21/150\n",
      "478/478 [==============================] - 22s 47ms/step - loss: 0.0391 - accuracy: 0.9882\n",
      "Epoch 22/150\n",
      "478/478 [==============================] - 24s 50ms/step - loss: 0.0422 - accuracy: 0.9872\n",
      "Epoch 23/150\n",
      "478/478 [==============================] - 22s 47ms/step - loss: 0.0298 - accuracy: 0.9912\n",
      "Epoch 24/150\n",
      "478/478 [==============================] - 23s 49ms/step - loss: 0.0419 - accuracy: 0.9867\n",
      "Epoch 25/150\n",
      "478/478 [==============================] - 23s 47ms/step - loss: 0.0392 - accuracy: 0.9878\n",
      "Epoch 26/150\n",
      "478/478 [==============================] - 23s 48ms/step - loss: 0.0296 - accuracy: 0.9919\n",
      "Epoch 27/150\n",
      "478/478 [==============================] - 23s 48ms/step - loss: 0.0255 - accuracy: 0.9930\n",
      "Epoch 28/150\n",
      "478/478 [==============================] - 23s 48ms/step - loss: 0.0405 - accuracy: 0.9898\n",
      "Epoch 29/150\n",
      "478/478 [==============================] - 23s 49ms/step - loss: 0.0383 - accuracy: 0.9897\n",
      "Epoch 30/150\n",
      "478/478 [==============================] - 24s 50ms/step - loss: 0.0394 - accuracy: 0.9884\n",
      "Epoch 31/150\n",
      "478/478 [==============================] - 23s 48ms/step - loss: 0.0314 - accuracy: 0.9906\n",
      "Epoch 32/150\n",
      "478/478 [==============================] - 22s 47ms/step - loss: 0.0286 - accuracy: 0.9927\n",
      "Epoch 33/150\n",
      "478/478 [==============================] - 23s 49ms/step - loss: 0.0207 - accuracy: 0.9941\n",
      "Epoch 34/150\n",
      "478/478 [==============================] - 23s 48ms/step - loss: 0.0355 - accuracy: 0.9897\n",
      "Epoch 35/150\n",
      "478/478 [==============================] - 23s 48ms/step - loss: 0.0410 - accuracy: 0.9890\n",
      "Epoch 36/150\n",
      "478/478 [==============================] - 23s 48ms/step - loss: 0.0169 - accuracy: 0.9960\n",
      "Epoch 37/150\n",
      "478/478 [==============================] - 23s 48ms/step - loss: 0.0295 - accuracy: 0.9920\n",
      "Epoch 38/150\n",
      "478/478 [==============================] - 23s 49ms/step - loss: 0.0184 - accuracy: 0.9946\n",
      "Epoch 39/150\n",
      "478/478 [==============================] - 23s 48ms/step - loss: 0.0236 - accuracy: 0.9935\n",
      "Epoch 40/150\n",
      "478/478 [==============================] - 24s 49ms/step - loss: 0.0135 - accuracy: 0.9964\n",
      "Epoch 41/150\n",
      "478/478 [==============================] - 22s 46ms/step - loss: 0.0107 - accuracy: 0.9973\n",
      "Epoch 42/150\n",
      "478/478 [==============================] - 24s 50ms/step - loss: 0.0250 - accuracy: 0.9941\n",
      "Epoch 43/150\n",
      "478/478 [==============================] - 22s 46ms/step - loss: 0.0305 - accuracy: 0.9914\n",
      "Epoch 44/150\n",
      "478/478 [==============================] - 25s 53ms/step - loss: 0.0259 - accuracy: 0.9925\n",
      "Epoch 45/150\n",
      "478/478 [==============================] - 16s 34ms/step - loss: 0.0112 - accuracy: 0.9963\n",
      "Epoch 46/150\n",
      "478/478 [==============================] - 15s 32ms/step - loss: 0.0247 - accuracy: 0.9939\n",
      "Epoch 47/150\n",
      "478/478 [==============================] - 15s 31ms/step - loss: 0.0091 - accuracy: 0.9977\n",
      "Epoch 48/150\n",
      "478/478 [==============================] - 15s 31ms/step - loss: 0.0092 - accuracy: 0.9979\n",
      "Epoch 49/150\n",
      "478/478 [==============================] - 15s 31ms/step - loss: 0.0056 - accuracy: 0.9991\n",
      "Epoch 50/150\n",
      "478/478 [==============================] - 15s 31ms/step - loss: 0.0106 - accuracy: 0.9965\n",
      "Epoch 51/150\n",
      "478/478 [==============================] - 15s 32ms/step - loss: 0.0129 - accuracy: 0.9965\n",
      "Epoch 52/150\n",
      "478/478 [==============================] - 15s 31ms/step - loss: 0.0059 - accuracy: 0.9990\n",
      "Epoch 53/150\n",
      "478/478 [==============================] - 15s 31ms/step - loss: 0.0139 - accuracy: 0.9967\n",
      "Epoch 54/150\n",
      "478/478 [==============================] - 15s 32ms/step - loss: 0.0209 - accuracy: 0.9944\n",
      "Epoch 55/150\n",
      "478/478 [==============================] - 15s 31ms/step - loss: 0.0186 - accuracy: 0.9946\n",
      "Epoch 56/150\n",
      "478/478 [==============================] - 15s 32ms/step - loss: 0.0121 - accuracy: 0.9966\n",
      "Epoch 57/150\n",
      "478/478 [==============================] - 15s 31ms/step - loss: 0.0142 - accuracy: 0.9966\n",
      "Epoch 58/150\n",
      "478/478 [==============================] - 15s 31ms/step - loss: 0.0102 - accuracy: 0.9972\n",
      "Epoch 59/150\n",
      "478/478 [==============================] - 15s 31ms/step - loss: 0.0295 - accuracy: 0.9922\n",
      "Epoch 60/150\n",
      "478/478 [==============================] - 15s 31ms/step - loss: 0.0111 - accuracy: 0.9975\n",
      "Epoch 61/150\n",
      "478/478 [==============================] - 15s 31ms/step - loss: 0.0182 - accuracy: 0.9950\n",
      "Epoch 62/150\n",
      "478/478 [==============================] - 15s 31ms/step - loss: 0.0123 - accuracy: 0.9965\n",
      "Epoch 63/150\n",
      "478/478 [==============================] - 15s 31ms/step - loss: 0.0104 - accuracy: 0.9973\n",
      "Epoch 64/150\n",
      "478/478 [==============================] - 15s 31ms/step - loss: 0.0192 - accuracy: 0.9946\n",
      "Epoch 65/150\n",
      "478/478 [==============================] - 15s 31ms/step - loss: 0.0117 - accuracy: 0.9971\n",
      "Epoch 66/150\n",
      "478/478 [==============================] - 15s 31ms/step - loss: 0.0145 - accuracy: 0.9958\n",
      "Epoch 67/150\n",
      "478/478 [==============================] - 15s 31ms/step - loss: 0.0213 - accuracy: 0.9945\n",
      "Epoch 68/150\n",
      "478/478 [==============================] - 15s 32ms/step - loss: 0.0116 - accuracy: 0.9966\n",
      "Epoch 69/150\n",
      "478/478 [==============================] - 15s 31ms/step - loss: 0.0085 - accuracy: 0.9980\n",
      "Epoch 70/150\n",
      "478/478 [==============================] - 15s 32ms/step - loss: 0.0157 - accuracy: 0.9958\n",
      "Epoch 71/150\n",
      "478/478 [==============================] - 15s 31ms/step - loss: 0.0049 - accuracy: 0.9992\n",
      "Epoch 72/150\n",
      "478/478 [==============================] - 15s 32ms/step - loss: 0.0045 - accuracy: 0.9990\n",
      "Epoch 73/150\n",
      "478/478 [==============================] - 15s 31ms/step - loss: 0.0069 - accuracy: 0.9985\n",
      "Epoch 74/150\n",
      "478/478 [==============================] - 15s 32ms/step - loss: 0.0022 - accuracy: 0.9999\n",
      "Epoch 75/150\n",
      "478/478 [==============================] - 15s 31ms/step - loss: 0.0024 - accuracy: 0.9996\n",
      "Epoch 76/150\n",
      "478/478 [==============================] - 15s 31ms/step - loss: 0.0022 - accuracy: 0.9999\n",
      "Epoch 77/150\n",
      "478/478 [==============================] - 15s 32ms/step - loss: 0.0015 - accuracy: 0.9998\n",
      "Epoch 78/150\n",
      "478/478 [==============================] - 15s 31ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 79/150\n",
      "478/478 [==============================] - 15s 32ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 80/150\n",
      "478/478 [==============================] - 15s 31ms/step - loss: 0.0028 - accuracy: 0.9995\n",
      "Epoch 81/150\n",
      "478/478 [==============================] - 15s 32ms/step - loss: 0.0024 - accuracy: 0.9996\n",
      "Epoch 82/150\n",
      "478/478 [==============================] - 15s 31ms/step - loss: 0.0026 - accuracy: 0.9995\n",
      "Epoch 83/150\n",
      "478/478 [==============================] - 15s 31ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 84/150\n",
      "478/478 [==============================] - 15s 32ms/step - loss: 0.0012 - accuracy: 0.9999\n",
      "Epoch 85/150\n",
      "478/478 [==============================] - 15s 31ms/step - loss: 0.0109 - accuracy: 0.9977\n",
      "Epoch 86/150\n",
      "478/478 [==============================] - 15s 31ms/step - loss: 0.0303 - accuracy: 0.9921\n",
      "Epoch 87/150\n",
      "478/478 [==============================] - 15s 31ms/step - loss: 0.0300 - accuracy: 0.9931\n",
      "Epoch 88/150\n",
      "478/478 [==============================] - 15s 32ms/step - loss: 0.0071 - accuracy: 0.9985\n",
      "Epoch 89/150\n",
      "478/478 [==============================] - 15s 31ms/step - loss: 0.0060 - accuracy: 0.9985\n",
      "Epoch 90/150\n",
      "478/478 [==============================] - 15s 32ms/step - loss: 0.0046 - accuracy: 0.9993\n",
      "Epoch 91/150\n",
      "478/478 [==============================] - 15s 32ms/step - loss: 0.0038 - accuracy: 0.9990\n",
      "Epoch 92/150\n",
      "478/478 [==============================] - 15s 31ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 93/150\n",
      "478/478 [==============================] - 15s 31ms/step - loss: 0.0057 - accuracy: 0.9985\n",
      "Epoch 94/150\n",
      "478/478 [==============================] - 15s 31ms/step - loss: 0.0058 - accuracy: 0.9986\n",
      "Epoch 95/150\n",
      "478/478 [==============================] - 15s 32ms/step - loss: 0.0057 - accuracy: 0.9987\n",
      "Epoch 96/150\n",
      "478/478 [==============================] - 15s 31ms/step - loss: 0.0019 - accuracy: 0.9996\n",
      "Epoch 97/150\n",
      "478/478 [==============================] - 15s 32ms/step - loss: 0.0023 - accuracy: 0.9997\n",
      "Epoch 98/150\n",
      "478/478 [==============================] - 15s 31ms/step - loss: 0.0114 - accuracy: 0.9975\n",
      "Epoch 99/150\n",
      "478/478 [==============================] - 15s 32ms/step - loss: 0.0035 - accuracy: 0.9997\n",
      "Epoch 100/150\n",
      "478/478 [==============================] - 15s 31ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 101/150\n",
      "478/478 [==============================] - 15s 32ms/step - loss: 0.0017 - accuracy: 0.9996\n",
      "Epoch 102/150\n",
      "478/478 [==============================] - 15s 32ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 103/150\n",
      "478/478 [==============================] - 15s 31ms/step - loss: 9.6799e-04 - accuracy: 1.0000\n",
      "Epoch 104/150\n",
      "478/478 [==============================] - 15s 31ms/step - loss: 0.0021 - accuracy: 0.9998\n",
      "Epoch 105/150\n",
      "478/478 [==============================] - 15s 31ms/step - loss: 0.0031 - accuracy: 0.9992\n",
      "Epoch 106/150\n",
      "478/478 [==============================] - 15s 31ms/step - loss: 0.0055 - accuracy: 0.9983\n",
      "Epoch 107/150\n",
      "478/478 [==============================] - 15s 31ms/step - loss: 0.0166 - accuracy: 0.9958\n",
      "Epoch 108/150\n",
      "478/478 [==============================] - 15s 31ms/step - loss: 0.0060 - accuracy: 0.9989\n",
      "Epoch 109/150\n",
      "478/478 [==============================] - 15s 32ms/step - loss: 0.0022 - accuracy: 0.9996\n",
      "Epoch 110/150\n",
      "478/478 [==============================] - 15s 31ms/step - loss: 0.0025 - accuracy: 0.9995\n",
      "Epoch 111/150\n",
      "478/478 [==============================] - 15s 32ms/step - loss: 0.0029 - accuracy: 0.9996\n",
      "Epoch 112/150\n",
      "478/478 [==============================] - 15s 31ms/step - loss: 0.0018 - accuracy: 0.9997\n",
      "Epoch 113/150\n",
      "478/478 [==============================] - 15s 31ms/step - loss: 0.0186 - accuracy: 0.9970\n",
      "Epoch 114/150\n",
      "478/478 [==============================] - 15s 32ms/step - loss: 0.0066 - accuracy: 0.9983\n",
      "Epoch 115/150\n",
      "478/478 [==============================] - 15s 31ms/step - loss: 0.0018 - accuracy: 0.9998\n",
      "Epoch 116/150\n",
      "478/478 [==============================] - 15s 32ms/step - loss: 0.0101 - accuracy: 0.9976\n",
      "Epoch 117/150\n",
      "478/478 [==============================] - 15s 31ms/step - loss: 0.0079 - accuracy: 0.9982\n",
      "Epoch 118/150\n",
      "478/478 [==============================] - 15s 32ms/step - loss: 0.0024 - accuracy: 0.9994\n",
      "Epoch 119/150\n",
      "478/478 [==============================] - 15s 31ms/step - loss: 0.0046 - accuracy: 0.9993\n",
      "Epoch 120/150\n",
      "478/478 [==============================] - 15s 31ms/step - loss: 0.0014 - accuracy: 0.9999\n",
      "Epoch 121/150\n",
      "478/478 [==============================] - 15s 32ms/step - loss: 0.0021 - accuracy: 0.9997\n",
      "Epoch 122/150\n",
      "478/478 [==============================] - 15s 31ms/step - loss: 0.0056 - accuracy: 0.9989\n",
      "Epoch 123/150\n",
      "478/478 [==============================] - 15s 31ms/step - loss: 0.0060 - accuracy: 0.9985\n",
      "Epoch 124/150\n",
      "478/478 [==============================] - 15s 31ms/step - loss: 0.0275 - accuracy: 0.9942\n",
      "Epoch 125/150\n",
      "478/478 [==============================] - 15s 32ms/step - loss: 0.0174 - accuracy: 0.9952\n",
      "Epoch 126/150\n",
      "478/478 [==============================] - 15s 31ms/step - loss: 0.0093 - accuracy: 0.9978\n",
      "Epoch 127/150\n",
      "478/478 [==============================] - 15s 31ms/step - loss: 0.0024 - accuracy: 0.9994\n",
      "Epoch 128/150\n",
      "478/478 [==============================] - 15s 32ms/step - loss: 0.0016 - accuracy: 0.9999\n",
      "Epoch 129/150\n",
      "478/478 [==============================] - 15s 31ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 130/150\n",
      "478/478 [==============================] - 15s 32ms/step - loss: 9.8407e-04 - accuracy: 1.0000\n",
      "Epoch 131/150\n",
      "478/478 [==============================] - 15s 31ms/step - loss: 0.0071 - accuracy: 0.9981\n",
      "Epoch 132/150\n",
      "478/478 [==============================] - 15s 32ms/step - loss: 0.0013 - accuracy: 0.9999\n",
      "Epoch 133/150\n",
      "478/478 [==============================] - 15s 31ms/step - loss: 0.0109 - accuracy: 0.9965\n",
      "Epoch 134/150\n",
      "478/478 [==============================] - 15s 31ms/step - loss: 0.0065 - accuracy: 0.9986\n",
      "Epoch 135/150\n",
      "478/478 [==============================] - 15s 32ms/step - loss: 0.0030 - accuracy: 0.9994\n",
      "Epoch 136/150\n",
      "478/478 [==============================] - 15s 31ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 137/150\n",
      "478/478 [==============================] - 15s 32ms/step - loss: 8.6060e-04 - accuracy: 1.0000\n",
      "Epoch 138/150\n",
      "478/478 [==============================] - 15s 31ms/step - loss: 9.1478e-04 - accuracy: 0.9999\n",
      "Epoch 139/150\n",
      "478/478 [==============================] - 15s 32ms/step - loss: 7.1143e-04 - accuracy: 1.0000\n",
      "Epoch 140/150\n",
      "478/478 [==============================] - 15s 31ms/step - loss: 0.0133 - accuracy: 0.9974\n",
      "Epoch 141/150\n",
      "478/478 [==============================] - 15s 32ms/step - loss: 0.0153 - accuracy: 0.9960\n",
      "Epoch 142/150\n",
      "478/478 [==============================] - 15s 32ms/step - loss: 0.0032 - accuracy: 0.9994\n",
      "Epoch 143/150\n",
      "478/478 [==============================] - 15s 31ms/step - loss: 0.0017 - accuracy: 0.9997\n",
      "Epoch 144/150\n",
      "478/478 [==============================] - 15s 32ms/step - loss: 0.0017 - accuracy: 0.9998\n",
      "Epoch 145/150\n",
      "478/478 [==============================] - 15s 32ms/step - loss: 0.0012 - accuracy: 0.9999\n",
      "Epoch 146/150\n",
      "478/478 [==============================] - 15s 31ms/step - loss: 6.5296e-04 - accuracy: 1.0000\n",
      "Epoch 147/150\n",
      "478/478 [==============================] - 15s 32ms/step - loss: 7.5333e-04 - accuracy: 1.0000\n",
      "Epoch 148/150\n",
      "478/478 [==============================] - 15s 32ms/step - loss: 6.4971e-04 - accuracy: 1.0000\n",
      "Epoch 149/150\n",
      "478/478 [==============================] - 15s 32ms/step - loss: 4.8648e-04 - accuracy: 1.0000\n",
      "Epoch 150/150\n",
      "478/478 [==============================] - 15s 31ms/step - loss: 6.0183e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./LSTM_model_reproduce/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./LSTM_model_reproduce/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f4f9969ed00> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f4ff0ba73a0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "using_saved_model = False\n",
    "\n",
    "if using_saved_model:\n",
    "    FCNN_model_ = load_model('./FCNN_model_reproduce')\n",
    "    LSTM_model = load_model('./LSTM_model_reproduce')\n",
    "else:  # fit the models\n",
    "    with tf.device('/GPU:0'):\n",
    "        FCNN_history = FCNN_model.fit(X_train_scaled_nw, y_train_nw, epochs=150,batch_size=100, shuffle=True)\n",
    "        FCNN_model.save('./FCNN_model_reproduce')\n",
    "        # Make sure to train LSTM on 'windowed' data\n",
    "        LSTM_history = LSTM_model.fit(X_train_scaled, y_train, epochs=150, batch_size=21, shuffle=False)\n",
    "        LSTM_model.save('./LSTM_model_reproduce')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
